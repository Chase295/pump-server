# üéØ ML Prediction Service - Projektplan

**Version:** 1.0  
**Datum:** 24. Dezember 2025  
**Status:** üìã Planungsphase

---

## üìã Executive Summary

Der **ML Prediction Service** ist ein Echtzeit-Vorhersage-Service, der automatisch Vorhersagen macht, sobald neue Daten in die `coin_metrics` Tabelle eingetragen werden. Er nutzt die trainierten Modelle aus dem ML Training Service und macht kontinuierlich Vorhersagen f√ºr alle aktiven Coins.

### Hauptziel

**Echtzeit-Vorhersagen f√ºr alle Coins, sobald neue Metriken verf√ºgbar sind.**

---

## üéØ Projekt-√úbersicht

### Was macht der Service?

1. **√úberwacht `coin_metrics`** auf neue Eintr√§ge
2. **L√§dt aktive Modelle** aus `ml_models` Tabelle
3. **Sammelt Historie** f√ºr jeden Coin (f√ºr Feature-Engineering)
4. **Bereitet Features auf** (gleiche Logik wie Training)
5. **Macht Vorhersagen** mit allen aktiven Modellen
6. **Speichert Ergebnisse** in `predictions` Tabelle
7. **Sendet Alerts** bei hoher Wahrscheinlichkeit (optional)

### Technologie-Stack

- **Backend:** FastAPI (Python 3.11) - wie ML Training Service
- **Datenbank:** PostgreSQL (extern, gleiche DB wie Training Service)
- **Event-Handling:** Polling oder Database Triggers
- **ML-Frameworks:** Scikit-learn, XGBoost (gleiche wie Training)
- **Monitoring:** Prometheus Metriken (wie beide Services)
- **API:** REST API f√ºr n8n Integration
- **Deployment:** Docker, Coolify (wie Training Service)

---

## üèóÔ∏è Architektur

### Projekt-Struktur

```
ml-prediction-service/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/                      # REST API (FastAPI)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py             # API Endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py            # Pydantic Schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validators.py         # Validierungs-Logik
‚îÇ   ‚îú‚îÄ‚îÄ database/                 # Datenbank-Operationen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connection.py         # DB-Verbindung (asyncpg)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py             # DB-Interaktionen
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ queries.py            # Spezielle Queries
‚îÇ   ‚îú‚îÄ‚îÄ prediction/               # Vorhersage-Logik
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engine.py             # Haupt-Vorhersage-Engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_manager.py      # Modell-Verwaltung (Laden, Caching)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_processor.py  # Feature-Aufbereitung
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ event_handler.py      # Event-Handling (neue coin_metrics)
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # Utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Konfiguration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py        # Custom Exceptions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py    # Logging-Setup
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py            # Prometheus Metriken
‚îÇ   ‚îî‚îÄ‚îÄ main.py                   # FastAPI App
‚îú‚îÄ‚îÄ docs/                         # Dokumentation
‚îú‚îÄ‚îÄ tests/                        # Test-Scripts
‚îú‚îÄ‚îÄ docker-compose.yml            # Docker-Konfiguration
‚îú‚îÄ‚îÄ Dockerfile                    # Docker-Image
‚îî‚îÄ‚îÄ requirements.txt              # Python-Abh√§ngigkeiten
```

### Datenfluss

```
coin_metrics (Neuer Eintrag)
    ‚Üì
Event Handler (erkennt neuen Eintrag)
    ‚Üì
Model Manager (l√§dt aktive Modelle)
    ‚Üì
Feature Processor (holt Historie, bereitet Features auf)
    ‚Üì
Prediction Engine (macht Vorhersagen)
    ‚Üì
Database (speichert in predictions Tabelle)
    ‚Üì
Optional: Alert/Webhook (bei hoher Wahrscheinlichkeit)
```

---

## ‚öôÔ∏è Kern-Funktionen

### 1. Modell-Verwaltung

#### 1.1 Aktive Modelle identifizieren

**Funktion:**
- Liest `ml_models` Tabelle
- Filtert nach `is_active = true`
- L√§dt Modell-Dateien (`.pkl`) aus Dateisystem
- Cached Modelle im Speicher

**Datenbank-Feld:**
```sql
ALTER TABLE ml_models ADD COLUMN is_active BOOLEAN DEFAULT false;
```

**Logik:**
- Beim Start: Alle aktiven Modelle laden
- Periodisch (z.B. alle 5 Min): Pr√ºfen auf neue/ge√§nderte Modelle
- Bei √Ñnderung: Modell neu laden oder aus Cache entfernen

#### 1.2 Modell-Caching

**Zweck:**
- Performance: Modelle nicht jedes Mal neu laden
- Speicher: Modelle im RAM halten

**Strategie:**
- LRU Cache (Least Recently Used)
- Max. 10 Modelle gleichzeitig im Speicher
- Automatisches Entladen bei Speichermangel

#### 1.3 Modell-Metadaten

**Gespeichert pro Modell:**
- Modell-ID, Name, Typ
- Features-Liste
- Feature-Engineering-Parameter
- Zeitbasierte Vorhersage-Parameter
- Threshold f√ºr Alerts (optional)

---

### 2. Event-Handling

#### 2.1 Neue Eintr√§ge erkennen

**Option A: Polling (Empfohlen f√ºr Start)**

**Funktion:**
- Pr√ºft alle X Sekunden (z.B. 30s) auf neue Eintr√§ge
- Merkt sich letzten verarbeiteten Timestamp
- Verarbeitet nur neue Eintr√§ge

**Vorteile:**
- Einfach umzusetzen
- Keine DB-√Ñnderungen n√∂tig
- Robust

**Nachteile:**
- Leicht verz√∂gert (nicht exakt Echtzeit)
- Overhead durch regelm√§√üige Queries

**SQL Query:**
```sql
SELECT DISTINCT mint, MAX(timestamp) as latest_timestamp
FROM coin_metrics
WHERE timestamp > $last_processed_timestamp
GROUP BY mint
ORDER BY latest_timestamp ASC
```

**Option B: Database Trigger (Sp√§ter)**

**Funktion:**
- PostgreSQL Trigger auf `coin_metrics` INSERT
- Trigger ruft HTTP-Webhook oder schreibt in Queue-Tabelle
- Service reagiert auf Event

**Vorteile:**
- Echtzeit (keine Verz√∂gerung)
- Effizient

**Nachteile:**
- Komplexer Setup
- DB-√Ñnderungen n√∂tig

**Empfehlung:** Start mit Polling, sp√§ter auf Trigger umstellen

#### 2.2 Batch-Verarbeitung

**Funktion:**
- Sammelt mehrere neue Eintr√§ge (z.B. 10-50)
- Verarbeitet in Batch
- Reduziert DB-Load

**Strategie:**
- Max. Wartezeit: 5 Sekunden
- Max. Batch-Gr√∂√üe: 50 Coins
- Verarbeitet sofort wenn Batch voll oder Wartezeit abgelaufen

---

### 3. Feature-Aufbereitung

#### 3.1 Historie sammeln

**Funktion:**
- F√ºr jeden Coin: Letzte N Eintr√§ge aus `coin_metrics` holen
- N = Max. ben√∂tigte Historie f√ºr Feature-Engineering
- Beispiel: 15 Eintr√§ge f√ºr `price_volatility_15`

**SQL Query:**
```sql
SELECT * FROM coin_metrics
WHERE mint = $coin_id
ORDER BY timestamp DESC
LIMIT 20
```

**Wichtig:**
- Nach `timestamp` sortiert (neueste zuerst)
- Genug Eintr√§ge f√ºr Feature-Engineering
- Falls zu wenig: Warnung, aber trotzdem verarbeiten

#### 3.2 Feature-Engineering

**Funktion:**
- Gleiche Logik wie im Training Service
- Nutzt `create_pump_detection_features()` aus Training Service
- Erstellt: ROC, Volatility, Velocity, Range, Change Features

**Code-Wiederverwendung:**
- Option 1: Shared Library (Python Package)
- Option 2: Code-Duplikation (einfacher, aber Wartung)
- Option 3: Import aus Training Service (wenn beide im gleichen Repo)

**Empfehlung:** Option 3 (Import) f√ºr Start, sp√§ter Option 1 (Shared Library)

#### 3.3 Feature-Validierung

**Funktion:**
- Pr√ºft ob alle ben√∂tigten Features vorhanden
- Pr√ºft ob Feature-Engineering Features erstellt wurden
- Warnung bei fehlenden Features

---

### 4. Vorhersage-Engine

#### 4.1 Vorhersage f√ºr ein Modell

**Ablauf:**
1. Modell aus Cache laden
2. Features in richtiger Reihenfolge vorbereiten
3. `model.predict()` ‚Üí Ja/Nein (0 oder 1)
4. `model.predict_proba()` ‚Üí Wahrscheinlichkeit (0.0 - 1.0)

**Wichtig:**
- Features m√ºssen in gleicher Reihenfolge sein wie beim Training
- Feature-Engineering muss identisch sein
- Modell-Typ muss unterst√ºtzt werden (Random Forest, XGBoost)

#### 4.2 Multi-Modell-Vorhersagen

**Funktion:**
- F√ºr jeden Coin: Vorhersage mit ALLEN aktiven Modellen
- Jedes Modell gibt eigene Vorhersage + Wahrscheinlichkeit
- Alle Ergebnisse speichern

**Vorteile:**
- Vergleich verschiedener Modelle
- Ensemble-Vorhersage m√∂glich (sp√§ter)
- Flexibilit√§t

#### 4.3 Ensemble-Vorhersage (Optional, sp√§ter)

**Funktion:**
- Kombiniert Vorhersagen mehrerer Modelle
- Gewichtete Durchschnitte
- Voting-Mechanismus

**Beispiel:**
- Modell A: 0.7 Wahrscheinlichkeit
- Modell B: 0.8 Wahrscheinlichkeit
- Ensemble: 0.75 (Durchschnitt) oder 0.8 (Max) oder 0.7 (Min)

---

### 5. Ergebnis-Speicherung

#### 5.1 Datenbank-Schema

**Neue Tabelle: `predictions`**

```sql
CREATE TABLE predictions (
    id BIGSERIAL PRIMARY KEY,
    coin_id VARCHAR(255) NOT NULL,
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    model_id BIGINT NOT NULL REFERENCES ml_models(id) ON DELETE CASCADE,
    
    -- Vorhersage
    prediction INTEGER NOT NULL,  -- 0 oder 1
    probability NUMERIC(5, 4) NOT NULL,  -- 0.0000 - 1.0000
    
    -- Features (optional, f√ºr Debugging)
    features JSONB,
    
    -- Metadaten
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- Indizes
    INDEX idx_predictions_coin_timestamp ON predictions(coin_id, timestamp DESC),
    INDEX idx_predictions_model ON predictions(model_id),
    INDEX idx_predictions_created ON predictions(created_at DESC)
);
```

**Zus√§tzliche Tabelle: `prediction_alerts` (Optional)**

```sql
CREATE TABLE prediction_alerts (
    id BIGSERIAL PRIMARY KEY,
    prediction_id BIGINT REFERENCES predictions(id) ON DELETE CASCADE,
    coin_id VARCHAR(255) NOT NULL,
    model_id BIGINT NOT NULL,
    probability NUMERIC(5, 4) NOT NULL,
    threshold NUMERIC(5, 4) NOT NULL,
    alert_sent BOOLEAN DEFAULT false,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

#### 5.2 Batch-Insert

**Funktion:**
- Sammelt mehrere Vorhersagen
- Insert in Batch (effizienter)
- Transaction f√ºr Konsistenz

**Performance:**
- Batch-Gr√∂√üe: 50-100 Vorhersagen
- Max. Wartezeit: 2 Sekunden

---

### 6. Alert-System (Optional)

#### 6.1 Threshold-basierte Alerts

**Funktion:**
- Wenn `probability > threshold` ‚Üí Alert erstellen
- Threshold konfigurierbar pro Modell
- Standard: 0.7 (70%)

**Konfiguration:**
```sql
ALTER TABLE ml_models ADD COLUMN alert_threshold NUMERIC(5, 4) DEFAULT 0.7;
```

#### 6.2 Alert-Kan√§le

**Optionen:**
- Webhook (HTTP POST)
- n8n Integration
- Database (prediction_alerts Tabelle)
- Logging

**Empfehlung:** Start mit Database, sp√§ter Webhook/n8n

---

## üîå API-Endpunkte

### 1. Modell-Verwaltung

#### `GET /api/models/active`
**Beschreibung:** Liste aller aktiven Modelle

**Response:**
```json
{
  "models": [
    {
      "id": 1,
      "name": "Finale",
      "model_type": "xgboost",
      "is_active": true,
      "alert_threshold": 0.7,
      "loaded": true,
      "last_prediction": "2025-12-24T12:00:00Z"
    }
  ]
}
```

#### `POST /api/models/{model_id}/activate`
**Beschreibung:** Modell aktivieren

**Response:**
```json
{
  "success": true,
  "message": "Modell aktiviert",
  "model_id": 1
}
```

#### `POST /api/models/{model_id}/deactivate`
**Beschreibung:** Modell deaktivieren

#### `POST /api/models/{model_id}/reload`
**Beschreibung:** Modell neu laden (z.B. nach Update)

### 2. Vorhersagen

#### `POST /api/predict`
**Beschreibung:** Manuelle Vorhersage f√ºr einen Coin

**Request:**
```json
{
  "coin_id": "ABC123...",
  "model_ids": [1, 2],  // Optional: Nur bestimmte Modelle
  "timestamp": "2025-12-24T12:00:00Z"  // Optional: Spezifischer Zeitpunkt
}
```

**Response:**
```json
{
  "coin_id": "ABC123...",
  "timestamp": "2025-12-24T12:00:00Z",
  "predictions": [
    {
      "model_id": 1,
      "model_name": "Finale",
      "prediction": 1,
      "probability": 0.85,
      "alert_triggered": true
    }
  ]
}
```

#### `GET /api/predictions`
**Beschreibung:** Liste aller Vorhersagen

**Query-Parameter:**
- `coin_id` (optional)
- `model_id` (optional)
- `min_probability` (optional)
- `limit` (optional, default: 100)
- `offset` (optional)

#### `GET /api/predictions/{prediction_id}`
**Beschreibung:** Details einer Vorhersage

#### `GET /api/predictions/latest/{coin_id}`
**Beschreibung:** Neueste Vorhersage f√ºr einen Coin

### 3. Status & Monitoring

#### `GET /api/health`
**Beschreibung:** Health Check

**Response:**
```json
{
  "status": "healthy",
  "active_models": 3,
  "predictions_last_hour": 150,
  "uptime_seconds": 3600,
  "db_connected": true
}
```

#### `GET /api/metrics`
**Beschreibung:** Prometheus Metriken

#### `GET /api/stats`
**Beschreibung:** Statistiken

**Response:**
```json
{
  "total_predictions": 10000,
  "predictions_last_hour": 150,
  "active_models": 3,
  "coins_tracked": 50,
  "avg_prediction_time_ms": 25
}
```

---

## üìä Monitoring & Metriken

### Prometheus Metriken

#### Counter
- `ml_predictions_total` - Gesamtanzahl Vorhersagen
- `ml_predictions_by_model_total{model_id, model_name}` - Vorhersagen pro Modell
- `ml_alerts_triggered_total{model_id}` - Anzahl Alerts
- `ml_errors_total{type}` - Fehler (model_load, prediction, db)

#### Gauge
- `ml_active_models` - Anzahl aktiver Modelle
- `ml_models_loaded` - Anzahl geladener Modelle
- `ml_coins_tracked` - Anzahl getrackter Coins
- `ml_prediction_duration_seconds` - Dauer einer Vorhersage
- `ml_db_connected` - DB-Verbindungsstatus
- `ml_service_uptime_seconds` - Uptime

#### Histogram
- `ml_prediction_duration_seconds` - Verteilung der Vorhersage-Dauer
- `ml_feature_processing_duration_seconds` - Feature-Aufbereitung Dauer
- `ml_model_load_duration_seconds` - Modell-Lade-Dauer

---

## üîÑ Workflow-Beispiele

### Workflow 1: Neuer Eintrag in coin_metrics

```
1. Event Handler erkennt neuen Eintrag
   ‚Üì
2. F√ºr jeden aktiven Coin:
   a. Hole Historie (letzte 20 Eintr√§ge)
   b. Bereite Features auf (inkl. Feature-Engineering)
   c. F√ºr jedes aktive Modell:
      - Lade Modell (aus Cache oder Datei)
      - Mache Vorhersage
      - Speichere Ergebnis
   ‚Üì
3. Optional: Pr√ºfe Alerts (wenn probability > threshold)
   ‚Üì
4. Optional: Sende Webhook/Alert
```

### Workflow 2: Modell aktivieren

```
1. API Request: POST /api/models/1/activate
   ‚Üì
2. Update ml_models: is_active = true
   ‚Üì
3. Lade Modell-Datei (.pkl)
   ‚Üì
4. Validiere Modell (Features, Parameter)
   ‚Üì
5. F√ºge zu Cache hinzu
   ‚Üì
6. Response: Erfolg
```

### Workflow 3: Batch-Verarbeitung

```
1. Sammle neue Eintr√§ge (max. 5 Sekunden oder 50 Coins)
   ‚Üì
2. Gruppiere nach Coin
   ‚Üì
3. F√ºr jeden Coin parallel:
   - Hole Historie
   - Bereite Features auf
   - Mache Vorhersagen
   ‚Üì
4. Batch-Insert in predictions Tabelle
   ‚Üì
5. Pr√ºfe Alerts f√ºr alle Vorhersagen
```

---

## üóÑÔ∏è Datenbank-Integration

### Beziehungen

```
ml_models (1) ‚îÄ‚îÄ‚îê
                ‚îú‚îÄ‚îÄ> predictions (N)
                ‚îî‚îÄ‚îÄ> prediction_alerts (N)
```

### Wichtige Queries

#### Aktive Modelle laden
```sql
SELECT id, name, model_type, model_file_path, features, params, 
       is_active, alert_threshold
FROM ml_models
WHERE is_active = true AND status = 'READY'
```

#### Historie f√ºr Coin holen
```sql
SELECT * FROM coin_metrics
WHERE mint = $coin_id
ORDER BY timestamp DESC
LIMIT 20
```

#### Neueste Vorhersage f√ºr Coin
```sql
SELECT p.*, m.name as model_name
FROM predictions p
JOIN ml_models m ON p.model_id = m.id
WHERE p.coin_id = $coin_id
ORDER BY p.timestamp DESC
LIMIT 1
```

---

## ‚öôÔ∏è Konfiguration

### Umgebungsvariablen

```bash
# Datenbank
DB_HOST=100.76.209.59
DB_PORT=5432
DB_NAME=crypto
DB_USER=postgres
DB_PASSWORD=...

# Modell-Storage
MODEL_STORAGE_PATH=/app/models  # Pfad zu .pkl Dateien

# Event-Handling
POLLING_INTERVAL_SECONDS=30
BATCH_SIZE=50
BATCH_TIMEOUT_SECONDS=5

# Feature-Engineering
FEATURE_HISTORY_SIZE=20  # Anzahl Eintr√§ge f√ºr Historie

# Performance
MAX_CONCURRENT_PREDICTIONS=10
MODEL_CACHE_SIZE=10

# Alerts
DEFAULT_ALERT_THRESHOLD=0.7
ALERT_WEBHOOK_URL=  # Optional

# Monitoring
METRICS_PORT=8000
HEALTH_CHECK_INTERVAL=10
```

---

## üß™ Testing-Strategie

### Unit Tests
- Feature-Aufbereitung
- Modell-Laden
- Vorhersage-Logik

### Integration Tests
- DB-Verbindung
- Modell-Laden aus DB
- Vorhersage-Speicherung

### End-to-End Tests
- Kompletter Workflow: Neuer Eintrag ‚Üí Vorhersage ‚Üí Speicherung
- Multi-Modell-Vorhersagen
- Alert-System

### Performance Tests
- Batch-Verarbeitung
- Concurrent Predictions
- Modell-Caching

---

## üöÄ Deployment

### Docker

**Dockerfile:**
- Python 3.11-slim
- FastAPI, asyncpg, scikit-learn, xgboost
- Prometheus Client
- Health Checks

**docker-compose.yml:**
- Service: ml-prediction-service
- Port: 8000 (API), 8001 (Metrics)
- Volumes: models/ (Shared mit Training Service?)
- Environment Variables

### Coolify

**Deployment:**
- √Ñhnlich wie ML Training Service
- Docker Compose oder Dockerfile
- Environment Variables setzen
- Health Checks konfigurieren

---

## üìà Erweiterungen (Sp√§ter)

### Phase 2: Ensemble-Vorhersagen
- Kombiniert mehrere Modelle
- Gewichtete Durchschnitte
- Voting-Mechanismus

### Phase 3: Real-time WebSocket
- WebSocket f√ºr Live-Updates
- Push-Vorhersagen an Clients
- Live-Dashboard

### Phase 4: Modell-Auto-Selection
- Automatisch bestes Modell w√§hlen
- Performance-Tracking
- Auto-Switching bei besserem Modell

### Phase 5: Advanced Alerts
- Mehrere Alert-Kan√§le
- Alert-Rules (z.B. "nur wenn 2 Modelle zustimmen")
- Alert-History

---

## üîó Integration mit bestehenden Services

### ML Training Service
- **Modell-Quelle:** L√§dt Modelle aus `ml_models` Tabelle
- **Modell-Dateien:** Shared Storage oder separate Pfade
- **Feature-Engineering:** Gleiche Logik (Code-Wiederverwendung)

### Pump Metrics Service
- **Daten-Quelle:** Liest aus `coin_metrics` Tabelle
- **Event-Trigger:** Reagiert auf neue Eintr√§ge
- **Monitoring:** √Ñhnliche Prometheus Metriken

### n8n
- **API:** REST API f√ºr n8n Workflows
- **Webhooks:** F√ºr Alerts
- **Integration:** Vollst√§ndig kompatibel

---

## ‚ö†Ô∏è Wichtige √úberlegungen

### 1. Code-Wiederverwendung

**Feature-Engineering:**
- Gleiche Logik wie Training Service
- Optionen: Shared Library, Import, Duplikation
- **Empfehlung:** Import f√ºr Start, sp√§ter Shared Library

### 2. Modell-Storage

**Optionen:**
- Shared Storage (NFS, S3)
- Training Service kopiert zu Prediction Service
- Beide Services haben Zugriff auf gleichen Pfad

**Empfehlung:** Shared Storage (z.B. Volume in Docker)

### 3. Performance

**Bottlenecks:**
- Modell-Laden (gel√∂st durch Caching)
- Feature-Engineering (kann langsam sein)
- DB-Queries (gel√∂st durch Batch-Processing)

**Optimierungen:**
- Modell-Caching
- Batch-Processing
- Parallel-Verarbeitung
- Connection Pooling

### 4. Skalierung

**Horizontal:**
- Mehrere Instanzen m√∂glich
- Jede Instanz verarbeitet verschiedene Coins
- Oder: Load Balancing

**Vertical:**
- Mehr RAM f√ºr mehr Modelle
- Mehr CPU f√ºr schnellere Verarbeitung

### 5. Fehlerbehandlung

**Strategien:**
- Retry bei DB-Fehlern
- Fallback bei Modell-Lade-Fehlern
- Logging aller Fehler
- Prometheus Metriken f√ºr Fehler

---

## üìù N√§chste Schritte

### Phase 1: MVP (Minimal Viable Product)

1. ‚úÖ Projekt-Struktur erstellen
2. ‚úÖ Datenbank-Schema erweitern (`is_active`, `predictions` Tabelle)
3. ‚úÖ Basis-API (Health, Models, Predict)
4. ‚úÖ Event-Handler (Polling)
5. ‚úÖ Feature-Aufbereitung (Import aus Training Service)
6. ‚úÖ Modell-Laden und Caching
7. ‚úÖ Vorhersage-Engine
8. ‚úÖ Ergebnis-Speicherung

### Phase 2: Erweiterungen

1. ‚úÖ Alert-System
2. ‚úÖ Batch-Verarbeitung optimieren
3. ‚úÖ Multi-Modell-Vorhersagen
4. ‚úÖ Performance-Optimierungen

### Phase 3: Production-Ready

1. ‚úÖ Umfassende Tests
2. ‚úÖ Monitoring & Alerting
3. ‚úÖ Dokumentation
4. ‚úÖ Deployment-Automation

---

## üéØ Erfolgs-Kriterien

### Funktionale Anforderungen
- ‚úÖ Erkennt neue Eintr√§ge in `coin_metrics`
- ‚úÖ L√§dt aktive Modelle automatisch
- ‚úÖ Macht Vorhersagen f√ºr alle aktiven Coins
- ‚úÖ Speichert Ergebnisse korrekt
- ‚úÖ API funktioniert mit n8n

### Performance-Anforderungen
- ‚úÖ < 1 Sekunde pro Vorhersage (inkl. Feature-Aufbereitung)
- ‚úÖ Unterst√ºtzt 10+ aktive Modelle gleichzeitig
- ‚úÖ Verarbeitet 100+ Coins pro Minute

### Qualit√§ts-Anforderungen
- ‚úÖ 99.9% Uptime
- ‚úÖ Fehlerbehandlung robust
- ‚úÖ Logging umfassend
- ‚úÖ Monitoring vollst√§ndig

---

## üìö Dokumentation

### Erforderliche Dokumentationen

1. **README.md** - Projekt-√úbersicht
2. **API_DOKUMENTATION.md** - API-Referenz
3. **DEPLOYMENT.md** - Deployment-Anleitung
4. **ARCHITECTURE.md** - Architektur-Details
5. **TESTING.md** - Testing-Strategie

---

**Status:** üìã Planungsphase abgeschlossen  
**N√§chster Schritt:** Implementierung starten

---

*Dieser Plan dient als Grundlage f√ºr die Implementierung. Alle Details sollten vor dem Start noch einmal durchgesprochen werden.*

