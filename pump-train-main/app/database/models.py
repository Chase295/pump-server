"""
Datenbank-Modelle f√ºr ML Training Service
Alle CRUD-Operationen f√ºr ml_models, ml_test_results, ml_comparisons, ml_jobs
"""
import logging
from typing import Optional, List, Dict, Any
from datetime import datetime
from app.database.connection import get_pool
from app.database.utils import to_jsonb, from_jsonb, convert_jsonb_fields
from app.utils.exceptions import DatabaseError

logger = logging.getLogger(__name__)

# ============================================================
# Hilfsfunktionen f√ºr Features
# ============================================================

async def get_all_available_features() -> List[str]:
    """
    Holt alle verf√ºgbaren Features:
    - Basis-Features aus der coin_metrics Tabelle
    - Engineered Features (generiert zur Laufzeit)

    Returns:
        Liste aller verf√ºgbaren Feature-Namen (29 base + 61 engineered = 90 total)
    """
    try:
        # 1. Basis-Features (statische Liste f√ºr Stabilit√§t)
        base_features = [
            'avg_trade_size_sol', 'bonding_curve_pct', 'buy_pressure_ratio', 'buy_volume_sol',
            'dev_sold_amount', 'is_koth', 'market_cap_close', 'max_single_buy_sol',
            'max_single_sell_sol', 'mint', 'net_volume_sol', 'num_buys', 'num_micro_trades',
            'num_sells', 'num_unique_wallets', 'num_whale_buys', 'num_whale_sells',
            'phase_id_at_time', 'price_close', 'price_high', 'price_low', 'price_open',
            'sell_volume_sol', 'unique_signer_ratio', 'virtual_sol_reserves',
            'volatility_pct', 'volume_sol', 'whale_buy_volume_sol', 'whale_sell_volume_sol'
        ]

        # 2. Engineered Features (statische Liste f√ºr Stabilit√§t)
        engineered_features = [
            # Dev-Tracking (5)
            'dev_sold_flag', 'dev_sold_cumsum', 'dev_sold_spike_5', 'dev_sold_spike_10', 'dev_sold_spike_15',
            # Buy Pressure (6)
            'buy_pressure_ma_5', 'buy_pressure_trend_5', 'buy_pressure_ma_10', 'buy_pressure_trend_10', 'buy_pressure_ma_15', 'buy_pressure_trend_15',
            # Whale Activity (4)
            'whale_net_volume', 'whale_activity_5', 'whale_activity_10', 'whale_activity_15',
            # Volatility (6)
            'volatility_ma_5', 'volatility_spike_5', 'volatility_ma_10', 'volatility_spike_10', 'volatility_ma_15', 'volatility_spike_15',
            # Wash Trading (3)
            'wash_trading_flag_5', 'wash_trading_flag_10', 'wash_trading_flag_15',
            # Volume Features (6)
            'net_volume_ma_5', 'volume_flip_5', 'net_volume_ma_10', 'volume_flip_10', 'net_volume_ma_15', 'volume_flip_15',
            # Price Momentum (6)
            'price_change_5', 'price_roc_5', 'price_change_10', 'price_roc_10', 'price_change_15', 'price_roc_15',
            # Volume Patterns (6)
            'volume_ratio_5', 'volume_spike_5', 'volume_ratio_10', 'volume_spike_10', 'volume_ratio_15', 'volume_spike_15',
            # Market Cap (3)
            'mcap_velocity_5', 'mcap_velocity_10', 'mcap_velocity_15',
            # ATH Features (15)
            'ath_distance_trend_5', 'ath_approach_5', 'ath_breakout_count_5', 'ath_breakout_volume_ma_5', 'ath_age_trend_5',
            'ath_distance_trend_10', 'ath_approach_10', 'ath_breakout_count_10', 'ath_breakout_volume_ma_10', 'ath_age_trend_10',
            'ath_distance_trend_15', 'ath_approach_15', 'ath_breakout_count_15', 'ath_breakout_volume_ma_15', 'ath_age_trend_15'
        ]

        # 3. Kombiniere beide Listen
        all_features = sorted(base_features + engineered_features)

        print(f"‚úÖ Features geladen: {len(base_features)} base + {len(engineered_features)} engineered = {len(all_features)} total")

        return all_features

    except Exception as e:
        print(f"‚ùå Fehler in get_all_available_features: {e}")
        # Fallback: Nur Basis-Features
        return [
            'avg_trade_size_sol', 'bonding_curve_pct', 'buy_pressure_ratio', 'buy_volume_sol',
            'dev_sold_amount', 'is_koth', 'market_cap_close', 'max_single_buy_sol',
            'max_single_sell_sol', 'mint', 'net_volume_sol', 'num_buys', 'num_micro_trades',
            'num_sells', 'num_unique_wallets', 'num_whale_buys', 'num_whale_sells',
            'phase_id_at_time', 'price_close', 'price_high', 'price_low', 'price_open',
            'sell_volume_sol', 'unique_signer_ratio', 'virtual_sol_reserves',
            'volatility_pct', 'volume_sol', 'whale_buy_volume_sol', 'whale_sell_volume_sol'
        ]

# ============================================================
# ml_models - CRUD Operationen
# ============================================================

async def ensure_unique_model_name(name: str) -> str:
    """
    Stellt sicher, dass der Modell-Name eindeutig ist.
    Falls der Name bereits existiert, wird ein eindeutiger Name generiert.
    
    Args:
        name: Urspr√ºnglicher Modell-Name
    
    Returns:
        Eindeutiger Modell-Name
    """
    pool = await get_pool()
    original_name = name
    
    # Pr√ºfe ob Name bereits existiert
    existing = await pool.fetchval(
        "SELECT id FROM ml_models WHERE name = $1 AND is_deleted = FALSE",
        name
    )
    
    if existing is None:
        # Name ist eindeutig
        return name
    
    # Name existiert bereits - generiere eindeutigen Namen
    import time
    timestamp = int(time.time() * 1000)  # Millisekunden f√ºr bessere Eindeutigkeit
    counter = 1
    
    while True:
        new_name = f"{original_name}_{timestamp}_{counter}"
        existing = await pool.fetchval(
            "SELECT id FROM ml_models WHERE name = $1 AND is_deleted = FALSE",
            new_name
        )
        if existing is None:
            logger.warning(f"‚ö†Ô∏è Modell-Name '{original_name}' bereits vorhanden - verwende '{new_name}'")
            return new_name
        counter += 1
        if counter > 1000:  # Sicherheitsgrenze
            # Fallback: Verwende nur Timestamp
            new_name = f"{original_name}_{timestamp}"
            logger.warning(f"‚ö†Ô∏è Konnte keinen eindeutigen Namen generieren - verwende '{new_name}'")
            return new_name

async def create_model(
    name: str,
    model_type: str,
    target_variable: str,
    train_start: datetime,
    train_end: datetime,
    features: List[str],
    target_operator: Optional[str] = None,  # Optional f√ºr zeitbasierte Vorhersagen
    target_value: Optional[float] = None,  # Optional f√ºr zeitbasierte Vorhersagen
    phases: Optional[List[int]] = None,
    params: Optional[Dict[str, Any]] = None,
    training_accuracy: Optional[float] = None,
    training_f1: Optional[float] = None,
    training_precision: Optional[float] = None,
    training_recall: Optional[float] = None,
    feature_importance: Optional[Dict[str, float]] = None,
    model_file_path: Optional[str] = None,
    description: Optional[str] = None,
    status: str = "TRAINING",
    cv_scores: Optional[Dict[str, Any]] = None,  # NEU: CV-Ergebnisse
    cv_overfitting_gap: Optional[float] = None,  # NEU: Overfitting-Gap
    roc_auc: Optional[float] = None,  # NEU: ROC-AUC
    mcc: Optional[float] = None,  # NEU: MCC
    fpr: Optional[float] = None,  # NEU: False Positive Rate
    fnr: Optional[float] = None,  # NEU: False Negative Rate
    confusion_matrix: Optional[Dict[str, int]] = None,  # NEU: Confusion Matrix
    simulated_profit_pct: Optional[float] = None,  # NEU: Simulierter Profit
    # Zeitbasierte Vorhersage-Parameter
    future_minutes: Optional[int] = None,
    price_change_percent: Optional[float] = None,
    target_direction: Optional[str] = None,
    # NEU: Rug-Detection-Metriken & Marktstimmung
    rug_detection_metrics: Optional[Dict[str, Any]] = None,  # NEU: Rug-Detection-Metriken
    market_context_enabled: Optional[bool] = False,  # NEU: Marktstimmung aktiviert
    use_flag_features: Optional[bool] = None  # NEU: Flag-Features aktivieren/deaktivieren
) -> int:
    """Erstellt ein neues Modell in ml_models"""
    pool = await get_pool()
    
    # ‚úÖ SICHERHEIT: Stelle sicher, dass der Name eindeutig ist
    # ‚ö†Ô∏è WICHTIG: Rufe ensure_unique_model_name NUR EINMAL auf, um Race Conditions zu vermeiden!
    original_name = name
    name = await ensure_unique_model_name(name)
    if name != original_name:
        logger.info(f"üìù Modell-Name angepasst: '{original_name}' ‚Üí '{name}'")
    
    # NEU: Konvertiere params zu Dict falls es ein String ist
    if params is not None and isinstance(params, str):
        from app.database.utils import from_jsonb
        params = from_jsonb(params) or {}
    
    # NEU: Hole use_flag_features aus params falls nicht explizit gesetzt
    # ‚ö†Ô∏è WICHTIG: use_flag_features wird NICHT √ºberschrieben, wenn es explizit gesetzt wurde (z.B. False)
    if use_flag_features is None:
        if params:
            use_flag_features = params.get('use_flag_features', True)
        else:
            use_flag_features = True  # Standard: aktiviert
    
    # Stelle sicher, dass use_flag_features auch in params ist (f√ºr Konsistenz)
    if params is None:
        params = {}
    params['use_flag_features'] = use_flag_features
    
    # Konvertiere Listen/Dicts zu JSONB-Strings (refactored: nutze Helper-Funktion)
    features_jsonb = to_jsonb(features)
    phases_jsonb = to_jsonb(phases)
    params_jsonb = to_jsonb(params)  # ‚ö†Ô∏è params enth√§lt jetzt use_flag_features
    feature_importance_jsonb = to_jsonb(feature_importance)
    cv_scores_jsonb = to_jsonb(cv_scores)
    confusion_matrix_jsonb = to_jsonb(confusion_matrix)
    rug_detection_metrics_jsonb = to_jsonb(rug_detection_metrics)
    
    # ‚ö†Ô∏è KRITISCH: Nur EIN INSERT-Versuch! Keine verschachtelten Retry-Bl√∂cke mehr!
    # Jeder erfolgreiche INSERT erstellt ein neues Modell - das f√ºhrt zu mehreren Modellen!
    max_retries = 2  # Maximal 2 Versuche (1x normal, 1x bei Duplikat-Fehler)
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            # Versuche zuerst mit allen Spalten (neue Schema-Version)
            model_id = await pool.fetchval(
                """
                INSERT INTO ml_models (
                    name, model_type, status,
                    target_variable, target_operator, target_value,
                    train_start, train_end,
                    features, phases, params,
                    training_accuracy, training_f1, training_precision, training_recall,
                    feature_importance, model_file_path, description,
                    cv_scores, cv_overfitting_gap,
                    roc_auc, mcc, fpr, fnr, confusion_matrix, simulated_profit_pct,
                    future_minutes, price_change_percent, target_direction,
                    rug_detection_metrics, market_context_enabled,
                    use_flag_features
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9::jsonb, $10::jsonb, $11::jsonb, 
                    $12, $13, $14, $15, $16::jsonb, $17, $18, $19::jsonb, $20,
                    $21, $22, $23, $24, $25::jsonb, $26, $27, $28, $29, $30::jsonb, $31, $32
                ) RETURNING id
                """,
                name, model_type, status,
                target_variable, target_operator, target_value,
                train_start, train_end,
                features_jsonb, phases_jsonb, params_jsonb,
                training_accuracy, training_f1, training_precision, training_recall,
                feature_importance_jsonb, model_file_path, description,
                cv_scores_jsonb, cv_overfitting_gap,
                roc_auc, mcc, fpr, fnr, confusion_matrix_jsonb, simulated_profit_pct,
                future_minutes, price_change_percent, target_direction,
                rug_detection_metrics_jsonb, market_context_enabled,
                use_flag_features  # NEU
            )
            # ‚úÖ Erfolgreich - beende sofort!
            logger.info(f"‚úÖ Modell erstellt: {name} (ID: {model_id})")
            return model_id
            
        except Exception as e:
            error_str = str(e).lower()
            
            # ‚úÖ Nur bei Duplikat-Fehler: Retry mit neuem Namen
            if 'duplicate key' in error_str and 'ml_models_name_key' in error_str:
                retry_count += 1
                if retry_count < max_retries:
                    logger.warning(f"‚ö†Ô∏è Duplikat-Fehler erkannt (Versuch {retry_count}) - generiere neuen eindeutigen Namen...")
                    name = await ensure_unique_model_name(original_name)
                    continue  # Versuche erneut mit neuem Namen
                else:
                    logger.error(f"‚ùå Duplikat-Fehler nach {max_retries} Versuchen - gebe auf")
                    raise DatabaseError(f"Konnte keinen eindeutigen Modell-Namen generieren nach {max_retries} Versuchen: {e}")
            
            # ‚úÖ Fallback: Pr√ºfe ob neue Spalten fehlen (alte Schema-Version)
            elif any(col in error_str for col in ['cv_scores', 'cv_overfitting_gap', 'roc_auc', 'mcc', 'fpr', 'fnr', 'confusion_matrix', 'simulated_profit_pct', 'rug_detection_metrics', 'market_context_enabled']):
                logger.warning(f"‚ö†Ô∏è Neue Metriken-Spalten nicht gefunden - verwende Fallback (ohne zus√§tzliche Metriken)")
                try:
                    # Fallback: Nur Standard-Spalten (ohne neue Metriken)
                    model_id = await pool.fetchval(
                        """
                        INSERT INTO ml_models (
                            name, model_type, status,
                            target_variable, target_operator, target_value,
                            train_start, train_end,
                            features, phases, params,
                            training_accuracy, training_f1, training_precision, training_recall,
                            feature_importance, model_file_path, description,
                            future_minutes, price_change_percent, target_direction
                        ) VALUES (
                            $1, $2, $3, $4, $5, $6, $7, $8, $9::jsonb, $10::jsonb, $11::jsonb, 
                            $12, $13, $14, $15, $16::jsonb, $17, $18, $19, $20, $21
                        ) RETURNING id
                        """,
                        name, model_type, status,
                        target_variable, target_operator, target_value,
                        train_start, train_end,
                        features_jsonb, phases_jsonb, params_jsonb,
                        training_accuracy, training_f1, training_precision, training_recall,
                        feature_importance_jsonb, model_file_path, description,
                        future_minutes, price_change_percent, target_direction
                    )
                    logger.info(f"‚úÖ Modell erstellt (Fallback): {name} (ID: {model_id})")
                    return model_id
                except Exception as e2:
                    error_str2 = str(e2).lower()
                    # Pr√ºfe auch im Fallback auf Duplikat-Fehler
                    if 'duplicate key' in error_str2 and 'ml_models_name_key' in error_str2:
                        retry_count += 1
                        if retry_count < max_retries:
                            logger.warning(f"‚ö†Ô∏è Duplikat-Fehler im Fallback (Versuch {retry_count}) - generiere neuen eindeutigen Namen...")
                            name = await ensure_unique_model_name(original_name)
                            continue
                        else:
                            raise DatabaseError(f"Konnte keinen eindeutigen Modell-Namen generieren nach {max_retries} Versuchen: {e2}")
                    else:
                        # Anderer Fehler im Fallback - weiterwerfen
                        logger.error(f"‚ùå Fehler im Fallback beim Erstellen des Modells: {e2}")
                        raise DatabaseError(f"Fehler beim Erstellen des Modells (Fallback): {e2}")
            else:
                # ‚ùå Alle anderen Fehler: Sofort abbrechen!
                logger.error(f"‚ùå Fehler beim Erstellen des Modells: {e}")
                raise DatabaseError(f"Fehler beim Erstellen des Modells: {e}")
    
    # Sollte nie erreicht werden, aber zur Sicherheit:
    raise DatabaseError(f"Unerwarteter Fehler: Konnte Modell nicht erstellen nach {max_retries} Versuchen")
    logger.info(f"‚úÖ Modell erstellt: {name} (ID: {model_id})")
    return model_id

async def get_model(model_id: int) -> Optional[Dict[str, Any]]:
    """Holt ein Modell aus der DB"""
    pool = await get_pool()
    row = await pool.fetchrow(
        "SELECT * FROM ml_models WHERE id = $1",
        model_id
    )
    if not row:
        return None
    
    # Konvertiere JSONB-Felder von Strings zu Python-Objekten (refactored: nutze Helper-Funktion)
    model_dict = dict(row)
    jsonb_fields = ['features', 'phases', 'params', 'feature_importance', 'cv_scores', 'confusion_matrix', 'rug_detection_metrics']  # NEU: rug_detection_metrics
    model_dict = convert_jsonb_fields(model_dict, jsonb_fields, direction="from")
    return model_dict

async def update_model(
    model_id: int,
    status: Optional[str] = None,
    name: Optional[str] = None,
    description: Optional[str] = None,
    training_accuracy: Optional[float] = None,
    training_f1: Optional[float] = None,
    training_precision: Optional[float] = None,
    training_recall: Optional[float] = None,
    feature_importance: Optional[Dict[str, float]] = None,
    model_file_path: Optional[str] = None,
    **kwargs
) -> bool:
    """Aktualisiert ein Modell"""
    pool = await get_pool()
    
    updates = []
    values = []
    param_num = 1
    
    if name is not None:
        updates.append(f"name = ${param_num}")
        values.append(name)
        param_num += 1
    if description is not None:
        updates.append(f"description = ${param_num}")
        values.append(description)
        param_num += 1
    if status is not None:
        updates.append(f"status = ${param_num}")
        values.append(status)
        param_num += 1
    if training_accuracy is not None:
        updates.append(f"training_accuracy = ${param_num}")
        values.append(training_accuracy)
        param_num += 1
    if training_f1 is not None:
        updates.append(f"training_f1 = ${param_num}")
        values.append(training_f1)
        param_num += 1
    if training_precision is not None:
        updates.append(f"training_precision = ${param_num}")
        values.append(training_precision)
        param_num += 1
    if training_recall is not None:
        updates.append(f"training_recall = ${param_num}")
        values.append(training_recall)
        param_num += 1
    if feature_importance is not None:
        updates.append(f"feature_importance = ${param_num}")
        values.append(feature_importance)
        param_num += 1
    if model_file_path is not None:
        updates.append(f"model_file_path = ${param_num}")
        values.append(model_file_path)
        param_num += 1
    
    if not updates:
        return False
    
    updates.append(f"updated_at = NOW()")
    values.append(model_id)
    
    query = f"UPDATE ml_models SET {', '.join(updates)} WHERE id = ${param_num}"
    await pool.execute(query, *values)
    logger.info(f"‚úÖ Modell aktualisiert: ID {model_id}")
    return True

async def list_models(
    status: Optional[str] = None,
    is_deleted: bool = False,
    limit: int = 100,
    offset: int = 0
) -> List[Dict[str, Any]]:
    """Listet Modelle mit optionalen Filtern"""
    pool = await get_pool()
    
    conditions = ["is_deleted = $1"]
    params = [is_deleted]
    param_num = 2
    
    if status:
        conditions.append(f"status = ${param_num}")
        params.append(status)
        param_num += 1
    
    where_clause = " AND ".join(conditions)
    params.extend([limit, offset])
    
    rows = await pool.fetch(
        f"""
        SELECT * FROM ml_models 
        WHERE {where_clause}
        ORDER BY created_at DESC
        LIMIT ${param_num} OFFSET ${param_num + 1}
        """,
        *params
    )
    # Konvertiere JSONB-Felder von Strings zu Python-Objekten (refactored: nutze Helper-Funktion)
    result = []
    jsonb_fields = ['features', 'phases', 'params', 'feature_importance', 'cv_scores', 'confusion_matrix']  # NEU: cv_scores, confusion_matrix
    for row in rows:
        model_dict = dict(row)
        model_dict = convert_jsonb_fields(model_dict, jsonb_fields, direction="from")
        result.append(model_dict)
    return result

async def delete_model(model_id: int) -> bool:
    """Soft-Delete: Markiert Modell als gel√∂scht"""
    pool = await get_pool()
    await pool.execute(
        "UPDATE ml_models SET is_deleted = TRUE, deleted_at = NOW() WHERE id = $1",
        model_id
    )
    logger.info(f"‚úÖ Modell gel√∂scht (soft): ID {model_id}")
    return True

# ============================================================
# ml_test_results - CRUD Operationen
# ============================================================

async def get_or_create_test_result(
    model_id: int,
    test_start: datetime,
    test_end: datetime,
    accuracy: Optional[float] = None,
    f1_score: Optional[float] = None,
    precision_score: Optional[float] = None,
    recall: Optional[float] = None,
    roc_auc: Optional[float] = None,
    # Zus√§tzliche Metriken (Phase 9)
    mcc: Optional[float] = None,
    fpr: Optional[float] = None,
    fnr: Optional[float] = None,
    simulated_profit_pct: Optional[float] = None,
    confusion_matrix: Optional[Dict[str, int]] = None,
    # Legacy: Confusion Matrix als einzelne Felder
    tp: Optional[int] = None,
    tn: Optional[int] = None,
    fp: Optional[int] = None,
    fn: Optional[int] = None,
    num_samples: Optional[int] = None,
    num_positive: Optional[int] = None,
    num_negative: Optional[int] = None,
    has_overlap: bool = False,
    overlap_note: Optional[str] = None,
    feature_importance: Optional[Dict[str, float]] = None,
    # Train vs. Test Vergleich (Phase 2)
    train_accuracy: Optional[float] = None,
    train_f1: Optional[float] = None,
    train_precision: Optional[float] = None,
    train_recall: Optional[float] = None,
    accuracy_degradation: Optional[float] = None,
    f1_degradation: Optional[float] = None,
    is_overfitted: Optional[bool] = None,
    # Test-Zeitraum Info (Phase 2)
    test_duration_days: Optional[float] = None
) -> int:
    """
    Erstellt ein Test-Ergebnis ODER gibt existierendes zur√ºck

    ‚úÖ Verhindert Duplikate durch vorherige Pr√ºfung (model_id + test_start + test_end)
    """
    pool = await get_pool()
    
    # Pr√ºfe zuerst, ob Test bereits existiert
    existing_test = await pool.fetchrow(
        """
        SELECT id FROM ml_test_results
        WHERE model_id = $1 AND test_start = $2 AND test_end = $3
        LIMIT 1
        """,
        model_id, test_start, test_end
    )
    
    if existing_test:
        test_id = existing_test['id']
        logger.info(f"‚ÑπÔ∏è Test-Ergebnis existiert bereits: ID {test_id} f√ºr Modell {model_id} (Zeitraum: {test_start} - {test_end})")
        return test_id
    
    # Konvertiere JSONB-Felder (refactored: nutze Helper-Funktion)
    confusion_matrix_jsonb = to_jsonb(confusion_matrix)
    feature_importance_jsonb = to_jsonb(feature_importance)
    
    # Erstelle neues Test-Ergebnis (Duplikat-Pr√ºfung erfolgt bereits oben)
    test_id = await pool.fetchval(
        """
        INSERT INTO ml_test_results (
            model_id, test_start, test_end,
            accuracy, f1_score, precision_score, recall, roc_auc,
            mcc, fpr, fnr, simulated_profit_pct, confusion_matrix,
            tp, tn, fp, fn,
            num_samples, num_positive, num_negative,
            has_overlap, overlap_note, feature_importance,
            train_accuracy, train_f1, train_precision, train_recall,
            accuracy_degradation, f1_degradation, is_overfitted,
            test_duration_days
        ) VALUES (
            $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13::jsonb, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23::jsonb,
            $24, $25, $26, $27, $28, $29, $30, $31
        )
        RETURNING id
        """,
        model_id, test_start, test_end,
        accuracy, f1_score, precision_score, recall, roc_auc,
        mcc, fpr, fnr, simulated_profit_pct, confusion_matrix_jsonb,
        tp, tn, fp, fn,
        num_samples, num_positive, num_negative,
        has_overlap, overlap_note, feature_importance_jsonb,
        train_accuracy, train_f1, train_precision, train_recall,
        accuracy_degradation, f1_degradation, is_overfitted,
        test_duration_days
    )
    logger.info(f"‚úÖ Test-Ergebnis erstellt: ID {test_id} f√ºr Modell {model_id}")
    return test_id

# Alias f√ºr R√ºckw√§rtskompatibilit√§t
async def create_test_result(*args, **kwargs) -> int:
    """Alias f√ºr get_or_create_test_result (R√ºckw√§rtskompatibilit√§t)"""
    return await get_or_create_test_result(*args, **kwargs)

async def get_test_result(test_id: int) -> Optional[Dict[str, Any]]:
    """Holt ein einzelnes Test-Ergebnis"""
    pool = await get_pool()
    row = await pool.fetchrow(
        "SELECT * FROM ml_test_results WHERE id = $1",
        test_id
    )
    if not row:
        return None
    # Konvertiere JSONB-Felder (refactored: nutze Helper-Funktion)
    test_dict = dict(row)
    jsonb_fields = ['feature_importance', 'confusion_matrix']
    test_dict = convert_jsonb_fields(test_dict, jsonb_fields, direction="from")
    return test_dict

async def list_all_test_results(
    limit: int = 100,
    offset: int = 0
) -> List[Dict[str, Any]]:
    """Listet alle Test-Ergebnisse"""
    import json
    pool = await get_pool()
    
    rows = await pool.fetch(
        """
        SELECT * FROM ml_test_results 
        ORDER BY created_at DESC
        LIMIT $1 OFFSET $2
        """,
        limit, offset
    )
    
    # Konvertiere JSONB-Felder von Strings zu Python-Objekten
    result = []
    for row in rows:
        test_dict = dict(row)
        jsonb_fields = ['feature_importance', 'confusion_matrix']
        for field in jsonb_fields:
            if field in test_dict and test_dict[field] is not None:
                if isinstance(test_dict[field], str):
                    try:
                        test_dict[field] = json.loads(test_dict[field])
                    except (json.JSONDecodeError, TypeError):
                        pass  # Falls bereits Python-Objekt oder Parsing fehlschl√§gt
        result.append(test_dict)
    
    return result

async def get_test_results(model_id: int) -> List[Dict[str, Any]]:
    """Holt alle Test-Ergebnisse f√ºr ein Modell"""
    pool = await get_pool()
    rows = await pool.fetch(
        "SELECT * FROM ml_test_results WHERE model_id = $1 ORDER BY created_at DESC",
        model_id
    )
    # Konvertiere JSONB-Felder (refactored: nutze Helper-Funktion)
    result = []
    jsonb_fields = ['feature_importance', 'confusion_matrix']
    for row in rows:
        test_dict = dict(row)
        test_dict = convert_jsonb_fields(test_dict, jsonb_fields, direction="from")
        result.append(test_dict)
    return result

# ============================================================
# ml_comparisons - CRUD Operationen
# ============================================================

async def create_comparison(
    model_a_id: int,
    model_b_id: int,
    test_start: datetime,
    test_end: datetime,
    test_a_id: Optional[int] = None,  # ‚úÖ NEU: Verweis auf Test-Ergebnis A
    test_b_id: Optional[int] = None,  # ‚úÖ NEU: Verweis auf Test-Ergebnis B
    num_samples: Optional[int] = None,
    a_accuracy: Optional[float] = None,
    a_f1: Optional[float] = None,
    a_precision: Optional[float] = None,
    a_recall: Optional[float] = None,
    b_accuracy: Optional[float] = None,
    b_f1: Optional[float] = None,
    b_precision: Optional[float] = None,
    b_recall: Optional[float] = None,
    winner_id: Optional[int] = None,
    # NEU: Zus√§tzliche Metriken f√ºr Modell A
    a_mcc: Optional[float] = None,
    a_fpr: Optional[float] = None,
    a_fnr: Optional[float] = None,
    a_simulated_profit_pct: Optional[float] = None,
    a_confusion_matrix: Optional[Dict[str, int]] = None,
    a_train_accuracy: Optional[float] = None,
    a_train_f1: Optional[float] = None,
    a_accuracy_degradation: Optional[float] = None,
    a_f1_degradation: Optional[float] = None,
    a_is_overfitted: Optional[bool] = None,
    a_test_duration_days: Optional[float] = None,
    # NEU: Zus√§tzliche Metriken f√ºr Modell B
    b_mcc: Optional[float] = None,
    b_fpr: Optional[float] = None,
    b_fnr: Optional[float] = None,
    b_simulated_profit_pct: Optional[float] = None,
    b_confusion_matrix: Optional[Dict[str, int]] = None,
    b_train_accuracy: Optional[float] = None,
    b_train_f1: Optional[float] = None,
    b_accuracy_degradation: Optional[float] = None,
    b_f1_degradation: Optional[float] = None,
    b_is_overfitted: Optional[bool] = None,
    b_test_duration_days: Optional[float] = None
) -> int:
    """Erstellt einen Modell-Vergleich mit allen Metriken"""
    import json
    pool = await get_pool()
    
    # Konvertiere Confusion Matrix zu JSONB (refactored: nutze Helper-Funktion)
    a_confusion_matrix_jsonb = to_jsonb(a_confusion_matrix)
    b_confusion_matrix_jsonb = to_jsonb(b_confusion_matrix)
    
    # ‚úÖ NEU: Pr√ºfe ob test_a_id und test_b_id gesetzt sind (neue Struktur)
    # Versuche zuerst neue Struktur, dann alte als Fallback
    try:
        # Versuche NEUE STRUKTUR zuerst
        comparison_id = await pool.fetchval(
            """
            INSERT INTO ml_comparisons (
                model_a_id, model_b_id, test_start, test_end,
                test_a_id, test_b_id,  -- ‚úÖ NEU: Verweise auf Test-Ergebnisse
                num_samples, winner_id
            ) VALUES (
                $1, $2, $3, $4, $5, $6, $7, $8
            ) RETURNING id
            """,
            model_a_id, model_b_id, test_start, test_end,
            test_a_id, test_b_id,
            num_samples, winner_id
        )
    except Exception as e:
        # Fallback auf ALTE STRUKTUR wenn neue Spalten nicht existieren
        logger.warning(f"Neue Vergleichs-Struktur nicht verf√ºgbar, verwende Fallback: {e}")
        comparison_id = await pool.fetchval(
            """
            INSERT INTO ml_comparisons (
                model_a_id, model_b_id, test_start, test_end,
                num_samples, winner_id
            ) VALUES (
                $1, $2, $3, $4, $5, $6
            ) RETURNING id
            """,
                model_a_id, model_b_id, test_start, test_end,
                num_samples, winner_id
        )

    except Exception:
        # ‚ö†Ô∏è ALTE STRUKTUR: Alle Metriken werden gespeichert (R√ºckw√§rtskompatibilit√§t)
        comparison_id = await pool.fetchval(
                """
                INSERT INTO ml_comparisons (
                    model_a_id, model_b_id, test_start, test_end, num_samples,
                    a_accuracy, a_f1, a_precision, a_recall,
                    b_accuracy, b_f1, b_precision, b_recall,
                    winner_id,
                    a_mcc, a_fpr, a_fnr, a_simulated_profit_pct, a_confusion_matrix,
                    a_train_accuracy, a_train_f1, a_accuracy_degradation, a_f1_degradation,
                    a_is_overfitted, a_test_duration_days,
                    b_mcc, b_fpr, b_fnr, b_simulated_profit_pct, b_confusion_matrix,
                    b_train_accuracy, b_train_f1, b_accuracy_degradation, b_f1_degradation,
                    b_is_overfitted, b_test_duration_days
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14,
                    $15, $16, $17, $18, $19::jsonb,
                    $20, $21, $22, $23, $24, $25,
                    $26, $27, $28, $29, $30::jsonb,
                    $31, $32, $33, $34, $35, $36
                ) RETURNING id
                """,
                model_a_id, model_b_id, test_start, test_end, num_samples,
                a_accuracy, a_f1, a_precision, a_recall,
                b_accuracy, b_f1, b_precision, b_recall,
                winner_id,
                a_mcc, a_fpr, a_fnr, a_simulated_profit_pct, a_confusion_matrix_jsonb,
                a_train_accuracy, a_train_f1, a_accuracy_degradation, a_f1_degradation,
                a_is_overfitted, a_test_duration_days,
                b_mcc, b_fpr, b_fnr, b_simulated_profit_pct, b_confusion_matrix_jsonb,
                b_train_accuracy, b_train_f1, b_accuracy_degradation, b_f1_degradation,
                b_is_overfitted, b_test_duration_days
            )
    except Exception as e:
        error_str = str(e).lower()
        if any(col in error_str for col in ['a_mcc', 'b_mcc', 'a_fpr', 'b_fpr', 'a_confusion_matrix', 'b_confusion_matrix']):
            # Fallback: Alte Spaltenstruktur (ohne neue Metriken)
            logger.warning(f"‚ö†Ô∏è Neue Vergleichs-Metriken-Spalten nicht gefunden - verwende Fallback (ohne zus√§tzliche Metriken)")
            comparison_id = await pool.fetchval(
                """
                INSERT INTO ml_comparisons (
                    model_a_id, model_b_id, test_start, test_end, num_samples,
                    a_accuracy, a_f1, a_precision, a_recall,
                    b_accuracy, b_f1, b_precision, b_recall,
                    winner_id
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14
                ) RETURNING id
                """,
                model_a_id, model_b_id, test_start, test_end, num_samples,
                a_accuracy, a_f1, a_precision, a_recall,
                b_accuracy, b_f1, b_precision, b_recall,
                winner_id
            )
        else:
            raise
    
    logger.info(f"‚úÖ Vergleich erstellt: ID {comparison_id} (Modell {model_a_id} vs {model_b_id})")
    return comparison_id


async def create_comparison_v2(
    model_ids: List[int],
    test_result_ids: List[int],
    results: List[Dict[str, Any]],
    test_start: datetime,
    test_end: datetime,
    num_samples: Optional[int] = None,
    winner_id: Optional[int] = None,
    winner_reason: Optional[str] = None
) -> int:
    """
    Erstellt einen Modell-Vergleich f√ºr bis zu 4 Modelle (v2)
    
    Speichert alle Daten als JSONB f√ºr flexible Modell-Anzahl.
    """
    pool = await get_pool()
    
    # Konvertiere zu JSONB
    model_ids_jsonb = to_jsonb(model_ids)
    test_result_ids_jsonb = to_jsonb(test_result_ids)
    results_jsonb = to_jsonb(results)
    
    # Legacy-Support: Erste zwei Modelle f√ºr model_a_id und model_b_id
    model_a_id = model_ids[0] if len(model_ids) >= 1 else None
    model_b_id = model_ids[1] if len(model_ids) >= 2 else None
    
    comparison_id = await pool.fetchval(
        """
        INSERT INTO ml_comparisons (
            model_a_id, model_b_id, test_start, test_end,
            model_ids, test_result_ids, results,
            num_samples, winner_id, winner_reason
        ) VALUES (
            $1, $2, $3, $4, $5::jsonb, $6::jsonb, $7::jsonb, $8, $9, $10
        ) RETURNING id
        """,
        model_a_id, model_b_id, test_start, test_end,
        model_ids_jsonb, test_result_ids_jsonb, results_jsonb,
        num_samples, winner_id, winner_reason
    )
    
    logger.info(f"‚úÖ Vergleich v2 erstellt: ID {comparison_id} ({len(model_ids)} Modelle)")
    return comparison_id


async def get_comparison(comparison_id: int) -> Optional[Dict[str, Any]]:
    """Holt einen Vergleich (unterst√ºtzt v1 und v2 Format)"""
    pool = await get_pool()
    
    # Einfache Query f√ºr alle Vergleiche
    row = await pool.fetchrow(
        "SELECT * FROM ml_comparisons WHERE id = $1",
        comparison_id
    )
    if not row:
        return None

    comparison_dict = dict(row)
    
    # Konvertiere JSONB-Felder
    jsonb_fields = ['a_confusion_matrix', 'b_confusion_matrix', 'model_ids', 'test_result_ids', 'results']
    comparison_dict = convert_jsonb_fields(comparison_dict, jsonb_fields, direction="from")

    return comparison_dict

async def list_comparisons(
    limit: int = 100,
    offset: int = 0
) -> List[Dict[str, Any]]:
    """Listet alle Vergleichs-Ergebnisse"""
    pool = await get_pool()

    rows = await pool.fetch(
        """
        SELECT * FROM ml_comparisons
        ORDER BY created_at DESC
        LIMIT $1 OFFSET $2
        """,
        limit, offset
    )

    # Konvertiere JSONB-Felder
    result = []
    jsonb_fields = ['a_confusion_matrix', 'b_confusion_matrix', 'model_ids', 'test_result_ids', 'results']
    for row in rows:
        comparison_dict = dict(row)
        comparison_dict = convert_jsonb_fields(comparison_dict, jsonb_fields, direction="from")
        result.append(comparison_dict)

    return result

async def delete_comparison(comparison_id: int) -> bool:
    """L√∂scht einen Vergleich"""
    pool = await get_pool()
    deleted = await pool.execute(
        "DELETE FROM ml_comparisons WHERE id = $1",
        comparison_id
    )
    logger.info(f"‚úÖ Vergleich gel√∂scht: ID {comparison_id}")
    return deleted == "DELETE 1"

async def delete_test_result(test_id: int) -> bool:
    """L√∂scht ein Test-Ergebnis"""
    pool = await get_pool()
    deleted = await pool.execute(
        "DELETE FROM ml_test_results WHERE id = $1",
        test_id
    )
    logger.info(f"‚úÖ Test-Ergebnis gel√∂scht: ID {test_id}")
    return deleted == "DELETE 1"

# ============================================================
# ml_jobs - CRUD Operationen
# ============================================================

async def create_job(
    job_type: str,
    priority: int = 5,
    train_model_type: Optional[str] = None,
    train_target_var: Optional[str] = None,
    train_operator: Optional[str] = None,
    train_value: Optional[float] = None,
    train_start: Optional[datetime] = None,
    train_end: Optional[datetime] = None,
    train_features: Optional[List[str]] = None,
    train_phases: Optional[List[int]] = None,
    train_params: Optional[Dict[str, Any]] = None,
    test_model_id: Optional[int] = None,
    test_start: Optional[datetime] = None,
    test_end: Optional[datetime] = None,
    compare_model_a_id: Optional[int] = None,
    compare_model_b_id: Optional[int] = None,
    compare_model_ids: Optional[List[int]] = None,  # NEU: Bis zu 4 Modelle
    compare_start: Optional[datetime] = None,
    compare_end: Optional[datetime] = None,
    progress_msg: Optional[str] = None,
    # Zeitbasierte Vorhersage-Parameter f√ºr Training
    train_future_minutes: Optional[int] = None,
    train_price_change_percent: Optional[float] = None,
    train_target_direction: Optional[str] = None,
    use_flag_features: Optional[bool] = None  # NEU: Flag-Features aktivieren/deaktivieren
) -> int:
    """Erstellt einen neuen Job"""
    pool = await get_pool()
    
    # Konvertiere Listen/Dicts zu JSONB-kompatiblen Werten (refactored: nutze Helper-Funktion)
    train_features_jsonb = to_jsonb(train_features)
    train_phases_jsonb = to_jsonb(train_phases)
    train_params_jsonb = to_jsonb(train_params)
    compare_model_ids_jsonb = to_jsonb(compare_model_ids)  # NEU
    
    # NEU: Hole use_flag_features aus train_params falls nicht explizit gesetzt
    if use_flag_features is None:
        if train_params:
            use_flag_features = train_params.get('use_flag_features', True)
        else:
            use_flag_features = True  # Standard: aktiviert
    # ‚ö†Ô∏è WICHTIG: use_flag_features wird NICHT √ºberschrieben, wenn es explizit gesetzt wurde (z.B. False)
    
    job_id = await pool.fetchval(
        """
        INSERT INTO ml_jobs (
            job_type, priority,
            train_model_type, train_target_var, train_operator, train_value,
            train_start, train_end, train_features, train_phases, train_params,
            test_model_id, test_start, test_end,
            compare_model_a_id, compare_model_b_id, compare_model_ids, compare_start, compare_end,
            progress_msg,
            train_future_minutes, train_price_change_percent, train_target_direction,
            use_flag_features
        ) VALUES (
            $1, $2, $3, $4, $5, $6, $7, $8, $9::jsonb, $10::jsonb, $11::jsonb, $12, $13, $14, $15, $16, $17::jsonb, $18, $19, $20, $21, $22, $23, $24
        ) RETURNING id
        """,
        job_type, priority,
        train_model_type, train_target_var, train_operator, train_value,
        train_start, train_end, train_features_jsonb, train_phases_jsonb, train_params_jsonb,
        test_model_id, test_start, test_end,
        compare_model_a_id, compare_model_b_id, compare_model_ids_jsonb, compare_start, compare_end,
        progress_msg,
        train_future_minutes, train_price_change_percent, train_target_direction,
        use_flag_features  # NEU
    )
    logger.info(f"‚úÖ Job erstellt: {job_type} (ID: {job_id})")
    return job_id

async def get_job(job_id: int) -> Optional[Dict[str, Any]]:
    """Holt einen Job"""
    pool = await get_pool()
    row = await pool.fetchrow(
        "SELECT * FROM ml_jobs WHERE id = $1",
        job_id
    )
    if not row:
        return None
    # Konvertiere JSONB-Felder von Strings zu Python-Objekten
    job_dict = dict(row)
    # Konvertiere JSONB-Felder von Strings zu Python-Objekten (refactored: nutze Helper-Funktion)
    jsonb_fields = ['train_features', 'train_phases', 'train_params', 'compare_model_ids']
    job_dict = convert_jsonb_fields(job_dict, jsonb_fields, direction="from")
    return job_dict

async def update_job_status(
    job_id: int,
    status: str,
    progress: Optional[float] = None,
    error_msg: Optional[str] = None,
    result_model_id: Optional[int] = None,
    result_test_id: Optional[int] = None,
    result_comparison_id: Optional[int] = None,
    progress_msg: Optional[str] = None,
    update_metrics: bool = True  # NEU: Metriken automatisch aktualisieren
) -> bool:
    """
    Aktualisiert Job-Status in DB und optional auch in Prometheus-Metriken
    
    Args:
        update_metrics: Wenn True, werden Prometheus-Metriken auch aktualisiert (f√ºr Live-Updates)
    """
    pool = await get_pool()
    
    updates = ["status = $1"]
    values = [status]
    param_num = 2
    
    if progress is not None:
        updates.append(f"progress = ${param_num}")
        values.append(progress)
        param_num += 1
    if error_msg is not None:
        updates.append(f"error_msg = ${param_num}")
        values.append(error_msg)
        param_num += 1
    if result_model_id is not None:
        updates.append(f"result_model_id = ${param_num}")
        values.append(result_model_id)
        param_num += 1
    if result_test_id is not None:
        updates.append(f"result_test_id = ${param_num}")
        values.append(result_test_id)
        param_num += 1
    if result_comparison_id is not None:
        updates.append(f"result_comparison_id = ${param_num}")
        values.append(result_comparison_id)
        param_num += 1
    if progress_msg is not None:
        updates.append(f"progress_msg = ${param_num}")
        values.append(progress_msg)
        param_num += 1
    
    # Timestamps
    if status == "RUNNING":
        updates.append("started_at = NOW()")
    elif status in ("COMPLETED", "FAILED", "CANCELLED"):
        updates.append("completed_at = NOW()")
    
    values.append(job_id)
    query = f"UPDATE ml_jobs SET {', '.join(updates)} WHERE id = ${param_num}"
    await pool.execute(query, *values)
    
    # ‚úÖ NEU: Aktualisiere auch Prometheus-Metriken f√ºr Live-Updates
    if update_metrics and progress is not None:
        try:
            from app.utils.metrics import update_job_metrics
            from datetime import datetime, timezone
            
            # Hole Job-Details f√ºr Metriken
            job = await get_job(job_id)
            if job:
                job_type = job.get('job_type', 'UNKNOWN')
                model_type = job.get('train_model_type') or job.get('test_model_id') or 'unknown'
                
                # Berechne Duration
                started_at = job.get('started_at')
                duration_seconds = None
                if started_at:
                    try:
                        if isinstance(started_at, str):
                            started_dt = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
                        else:
                            started_dt = started_at
                        if started_dt.tzinfo is None:
                            started_dt = started_dt.replace(tzinfo=timezone.utc)
                        duration_seconds = (datetime.now(timezone.utc) - started_dt).total_seconds()
                    except:
                        pass
                
                # Update Metriken direkt
                update_job_metrics(
                    job_id=job_id,
                    job_type=job_type,
                    model_type=model_type,
                    status=status,
                    progress=progress * 100.0,  # Konvertiere 0.1 ‚Üí 10.0
                    duration_seconds=duration_seconds
                )
        except Exception as e:
            # Fehler bei Metriken-Update sollte Job-Update nicht blockieren
            logger.warning(f"‚ö†Ô∏è Fehler beim Aktualisieren der Metriken f√ºr Job {job_id}: {e}")
    
    logger.info(f"‚úÖ Job aktualisiert: ID {job_id} ‚Üí {status} (Progress: {progress*100 if progress else 'N/A'}%)")
    return True

async def list_jobs(
    status: Optional[str] = None,
    job_type: Optional[str] = None,
    limit: int = 100,
    offset: int = 0
) -> List[Dict[str, Any]]:
    """Listet Jobs mit optionalen Filtern"""
    pool = await get_pool()
    
    conditions = []
    params = []
    param_num = 1
    
    if status:
        conditions.append(f"status = ${param_num}")
        params.append(status)
        param_num += 1
    
    if job_type:
        conditions.append(f"job_type = ${param_num}")
        params.append(job_type)
        param_num += 1
    
    where_clause = " AND ".join(conditions) if conditions else "1=1"
    params.extend([limit, offset])
    
    rows = await pool.fetch(
        f"""
        SELECT * FROM ml_jobs 
        WHERE {where_clause}
        ORDER BY created_at DESC
        LIMIT ${param_num} OFFSET ${param_num + 1}
        """,
        *params
    )
    # Konvertiere JSONB-Felder von Strings zu Python-Objekten
    result = []
    for row in rows:
        job_dict = dict(row)
        # JSONB-Felder konvertieren (inkl. compare_model_ids f√ºr Vergleichs-Jobs)
        jsonb_fields = ['train_features', 'train_phases', 'train_params', 'compare_model_ids']
        job_dict = convert_jsonb_fields(job_dict, jsonb_fields, direction="from")
        result.append(job_dict)
    return result

async def get_next_pending_job() -> Optional[Dict[str, Any]]:
    """
    Holt n√§chsten PENDING Job und setzt Status ATOMIC auf RUNNING
    
    ‚úÖ WICHTIG: Verhindert Race Conditions - Job wird sofort auf RUNNING gesetzt,
    damit er nicht von mehreren Workern gleichzeitig verarbeitet wird!
    """
    pool = await get_pool()
    
    # ‚úÖ ATOMIC: Hole Job UND setze Status auf RUNNING in einer Transaktion
    row = await pool.fetchrow(
        """
        UPDATE ml_jobs 
        SET status = 'RUNNING', 
            started_at = COALESCE(started_at, NOW()),
            progress = 0.0
        WHERE id = (
            SELECT id FROM ml_jobs 
            WHERE status = 'PENDING'
            ORDER BY priority DESC, created_at ASC
            LIMIT 1
            FOR UPDATE SKIP LOCKED
        )
        RETURNING *
        """
    )
    if not row:
        return None
    # Konvertiere JSONB-Felder
    job_dict = dict(row)
    jsonb_fields = ['train_features', 'train_phases', 'train_params', 'compare_model_ids']
    job_dict = convert_jsonb_fields(job_dict, jsonb_fields, direction="from")
    return job_dict

# ============================================================
# ref_model_types - Helper Funktionen
# ============================================================

async def get_model_type_defaults(model_type: str) -> Dict[str, Any]:
    """Lade Default-Parameter f√ºr Modell-Typ aus ref_model_types"""
    import json
    pool = await get_pool()
    row = await pool.fetchrow(
        "SELECT default_params FROM ref_model_types WHERE name = $1",
        model_type
    )
    if row and row["default_params"]:
        # Refactored: nutze Helper-Funktion
        params = from_jsonb(row["default_params"])
        return params if params is not None else {}
    return {}

async def get_coin_phases() -> List[Dict[str, Any]]:
    """
    Lade alle Coin-Phasen aus ref_coin_phases mit interval_seconds
    
    Returns:
        Liste von Dicts mit: id, name, interval_seconds, max_age_minutes
    """
    pool = await get_pool()
    try:
        rows = await pool.fetch(
            "SELECT id, name, interval_seconds, max_age_minutes FROM ref_coin_phases ORDER BY id ASC"
        )
        phases = []
        for row in rows:
            phases.append({
                "id": row["id"],
                "name": row["name"],
                "interval_seconds": row["interval_seconds"],
                "max_age_minutes": row["max_age_minutes"]
            })
        logger.info(f"‚úÖ {len(phases)} Phasen geladen")
        return phases
    except Exception as e:
        logger.error(f"‚ùå Fehler beim Laden der Phasen: {e}")
        # Fallback: Leere Liste oder Standard-Phasen
        return []

async def get_phase_intervals() -> Dict[int, int]:
    """
    Lade interval_seconds pro Phase als Dict (f√ºr schnellen Zugriff)
    
    Returns:
        Dict: {phase_id: interval_seconds}
    """
    pool = await get_pool()
    try:
        rows = await pool.fetch(
            "SELECT id, interval_seconds FROM ref_coin_phases"
        )
        intervals = {row["id"]: row["interval_seconds"] for row in rows}
        logger.debug(f"‚úÖ {len(intervals)} Phase-Intervalle geladen")
        return intervals
    except Exception as e:
        logger.error(f"‚ùå Fehler beim Laden der Phase-Intervalle: {e}")
        return {}

