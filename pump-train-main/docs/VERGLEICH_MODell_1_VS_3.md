# Vergleich: Modell 1 ("Finale") vs. Modell 3 ("Final Test Modell")

## Warum hatte Modell 1 viel bessere Werte?

### ğŸ” Hauptunterschiede

| Aspekt | Modell 1 ("Finale") | Modell 3 ("Final Test Modell") | Auswirkung |
|--------|---------------------|--------------------------------|------------|
| **Features** | **20 Features** | **3 Features** | âš ï¸ **KRITISCH** |
| **Feature-Engineering** | âœ… **Aktiviert** | âŒ **Deaktiviert** | âš ï¸ **KRITISCH** |
| **Modell-Typ** | **XGBoost** | **Random Forest** | âš ï¸ Wichtig |
| **Trainings-Zeitraum** | **3 Tage** (2025-12-21 bis 2025-12-24) | **1 Tag** (2025-12-22) | âš ï¸ Wichtig |
| **n_estimators** | 100 | 50 | Gering |
| **max_depth** | 6 | 5 | Gering |

---

## ğŸ“Š Detaillierter Vergleich

### 1. Features - Der grÃ¶ÃŸte Unterschied!

#### Modell 1: 20 Features (mit Feature-Engineering)

```
Basis-Features:
- price_open
- price_high
- price_low
- price_close
- volume_sol

Feature-Engineering Features (15 zusÃ¤tzliche):
- price_roc_10 (Rate of Change Ã¼ber 10 Perioden)
- price_roc_5
- price_roc_15
- price_range_5 (Preisspanne Ã¼ber 5 Perioden)
- price_range_10
- price_range_15
- price_volatility_5 (VolatilitÃ¤t Ã¼ber 5 Perioden)
- price_volatility_10
- price_volatility_15
- price_change_5
- price_change_10
- price_change_15
- mcap_velocity_5 (Market Cap Geschwindigkeit)
- mcap_velocity_10
- mcap_velocity_15
```

**Warum wichtig?**
- Feature-Engineering erstellt **Muster-Erkennungs-Features**
- Diese Features helfen dem Modell, **Trends und Momentum** zu erkennen
- Ohne diese Features kann das Modell nur **statische Preise** sehen, nicht **Bewegungen**

#### Modell 3: Nur 3 Features (OHNE Feature-Engineering)

```
- price_open
- price_high
- price_low
```

**Problem:**
- âŒ **Kein `price_close`** - fehlt komplett!
- âŒ **Keine Feature-Engineering Features**
- âŒ **Keine Momentum-Features**
- âŒ **Keine VolatilitÃ¤ts-Features**

**Das Modell sieht nur:**
- Aktueller Preis (open, high, low)
- **KEINE Trends**
- **KEINE Bewegungen**
- **KEINE Muster**

---

### 2. Feature-Engineering - Der entscheidende Faktor

#### Modell 1: Feature-Engineering âœ… AKTIVIERT

```json
{
  "params": {
    "use_engineered_features": true,
    "feature_engineering_windows": [5, 10, 15]
  }
}
```

**Was passiert:**
- Das System erstellt automatisch **15 zusÃ¤tzliche Features**
- Diese Features zeigen **Trends, Momentum, VolatilitÃ¤t**
- Das Modell kann **Muster erkennen**, die auf eine 30% Steigerung in 5 Minuten hindeuten

#### Modell 3: Feature-Engineering âŒ DEAKTIVIERT

```json
{
  "params": {
    "use_engineered_features": false
  }
}
```

**Was passiert:**
- **KEINE zusÃ¤tzlichen Features**
- Das Modell sieht nur **statische Preise**
- **KEINE Muster-Erkennung mÃ¶glich**

---

### 3. Modell-Typ

#### Modell 1: XGBoost

**Vorteile:**
- âœ… **Besser bei komplexen Mustern**
- âœ… **Besser bei Feature-Interaktionen**
- âœ… **Besser bei unausgewogenen Daten**
- âœ… **Gradient Boosting** - lernt schrittweise aus Fehlern

#### Modell 3: Random Forest

**Nachteile:**
- âš ï¸ **Weniger gut bei komplexen Mustern**
- âš ï¸ **Weniger gut bei Feature-Interaktionen**
- âš ï¸ **Bagging** - weniger adaptiv als Boosting

**Aber:** Das ist nicht der Hauptgrund! Der Hauptgrund ist die **fehlenden Features**.

---

### 4. Trainings-Zeitraum

#### Modell 1: 3 Tage Training

- **Mehr Daten** = mehr Muster gelernt
- **Mehr Variation** = bessere Generalisierung

#### Modell 3: 1 Tag Training

- **Weniger Daten** = weniger Muster gelernt
- **Weniger Variation** = schlechtere Generalisierung

**Aber:** Auch das ist nicht der Hauptgrund! Der Hauptgrund ist die **fehlenden Features**.

---

## ğŸ¯ Warum macht Modell 3 keine positiven Vorhersagen?

### Das Problem im Detail:

1. **Zu wenige Features (nur 3)**
   - Das Modell sieht nur: `price_open`, `price_high`, `price_low`
   - **Fehlt:** `price_close` (wichtigster Feature!)
   - **Fehlt:** Alle Feature-Engineering Features

2. **Keine Muster-Erkennung mÃ¶glich**
   - Ohne Feature-Engineering kann das Modell keine **Trends** erkennen
   - Ohne Feature-Engineering kann das Modell kein **Momentum** erkennen
   - Ohne Feature-Engineering kann das Modell keine **VolatilitÃ¤t** erkennen

3. **Das Modell "denkt":**
   - "Ich sehe nur statische Preise"
   - "Ich kann keine Muster erkennen, die auf eine 30% Steigerung hindeuten"
   - "Es ist sicherer, immer 'negativ' zu sagen"

### Warum macht Modell 1 positive Vorhersagen?

1. **20 Features (inkl. Feature-Engineering)**
   - Das Modell sieht: Preise, Trends, Momentum, VolatilitÃ¤t
   - Das Modell kann **Muster erkennen**

2. **Feature-Engineering Features zeigen:**
   - `price_roc_10`: "Preis steigt Ã¼ber 10 Perioden"
   - `price_volatility_15`: "Hohe VolatilitÃ¤t"
   - `mcap_velocity_5`: "Market Cap steigt schnell"
   - Diese Features helfen dem Modell, **positive FÃ¤lle zu erkennen**

3. **Das Modell "denkt":**
   - "Ich sehe Muster, die auf eine Steigerung hindeuten"
   - "Ich kann positive FÃ¤lle erkennen"
   - "Ich mache positive Vorhersagen"

---

## ğŸ“Š Training-Metriken Vergleich

### Modell 1: Gute Performance

```
TP: 3.577  âœ… Macht positive Vorhersagen
TN: 8.845
FP: 2.390
FN: 2.432

Accuracy: 0.7204
F1-Score: 0.5974  âœ… Gut!
Precision: 0.5995
Recall: 0.5953
```

**Warum gut?**
- âœ… **TP > 0**: Macht positive Vorhersagen
- âœ… **F1-Score > 0.5**: Gute Balance zwischen Precision und Recall
- âœ… **Recall > 0.5**: Erkennt mehr als die HÃ¤lfte der positiven FÃ¤lle

### Modell 3: Schlechte Performance

```
TP: 0  âŒ Macht KEINE positiven Vorhersagen
TN: 4.217
FP: 0
FN: 2.357

Accuracy: 0.6415
F1-Score: 0.0000  âŒ Schlecht!
Precision: 0.0000
Recall: 0.0000
```

**Warum schlecht?**
- âŒ **TP = 0**: Macht KEINE positiven Vorhersagen
- âŒ **F1-Score = 0**: Keine nÃ¼tzliche Vorhersage
- âŒ **Recall = 0**: Erkennt KEINE positiven FÃ¤lle

---

## ğŸ“Š Test-Ergebnisse Vergleich

### Modell 1 Test: Gute Performance

```
TP: 17  âœ… Macht positive Vorhersagen
TN: 138
FP: 69
FN: 15

Accuracy: 0.6485
F1-Score: 0.2881  âœ… Gut (fÃ¼r schwierige Aufgabe)
```

**Warum gut?**
- âœ… **TP > 0**: Macht positive Vorhersagen
- âœ… **F1-Score > 0**: NÃ¼tzliche Vorhersagen
- âš ï¸ **F1-Score niedrig (0.2881)**: Aber das ist normal fÃ¼r eine sehr schwierige Aufgabe (30% in 5 Min)

### Modell 3 Test: Schlechte Performance

```
TP: 0  âŒ Macht KEINE positiven Vorhersagen
TN: 36.830
FP: 0
FN: 20.296

Accuracy: 0.6447
F1-Score: 0.0000  âŒ Schlecht!
```

**Warum schlecht?**
- âŒ **TP = 0**: Macht KEINE positiven Vorhersagen
- âŒ **F1-Score = 0**: Keine nÃ¼tzliche Vorhersage
- âš ï¸ **Accuracy Ã¤hnlich (0.6447 vs. 0.6485)**: Aber das ist nur, weil das Modell immer "negativ" sagt und es mehr negative als positive FÃ¤lle gibt

---

## ğŸ¯ Fazit

### Warum hatte Modell 1 bessere Werte?

**Hauptgrund: Feature-Engineering aktiviert!**

1. âœ… **20 Features** (inkl. 15 Feature-Engineering Features)
2. âœ… **Muster-Erkennung mÃ¶glich** (Trends, Momentum, VolatilitÃ¤t)
3. âœ… **Positive Vorhersagen mÃ¶glich** (TP > 0)
4. âœ… **Gute F1-Scores** (0.5974 Training, 0.2881 Test)

### Warum hatte Modell 3 schlechte Werte?

**Hauptgrund: Feature-Engineering deaktiviert!**

1. âŒ **Nur 3 Features** (ohne Feature-Engineering)
2. âŒ **Keine Muster-Erkennung mÃ¶glich**
3. âŒ **Keine positiven Vorhersagen** (TP = 0)
4. âŒ **F1-Score = 0** (nicht nÃ¼tzlich)

### Was bedeutet das?

**âœ… Die Validierung ist trotzdem korrekt!**

- Beide Modelle wurden korrekt trainiert
- Beide Modelle wurden korrekt getestet
- Alle Berechnungen sind mathematisch korrekt

**Aber:** Modell 3 ist **nicht nÃ¼tzlich**, weil es keine positiven Vorhersagen macht.

### Empfehlung

**FÃ¼r bessere Ergebnisse:**

1. âœ… **Feature-Engineering aktivieren**
   ```json
   {
     "params": {
       "use_engineered_features": true,
       "feature_engineering_windows": [5, 10, 15]
     }
   }
   ```

2. âœ… **Alle Basis-Features verwenden**
   ```json
   {
     "features": [
       "price_open", "price_high", "price_low", "price_close",
       "volume_sol", "market_cap_close"
     ]
   }
   ```

3. âœ… **XGBoost verwenden** (statt Random Forest)

4. âœ… **LÃ¤ngeren Trainings-Zeitraum** (3 Tage statt 1 Tag)

---

**Wichtig:** Der Unterschied liegt nicht im Code, sondern in den **Modell-Parametern**!

Der Code funktioniert zu 100% korrekt - Modell 1 hatte einfach bessere Parameter! ğŸ¯

