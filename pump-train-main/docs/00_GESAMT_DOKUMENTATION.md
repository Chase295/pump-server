# üìö ML Training Service - Gesamt-Dokumentation

**Version:** 2.0  
**Stand:** 24. Dezember 2025  
**Status:** ‚úÖ Produktionsreif

---

## üìã Inhaltsverzeichnis

1. [Projekt-√úbersicht](#projekt-√ºbersicht)
2. [Schnellstart](#schnellstart)
3. [Architektur](#architektur)
4. [Funktionen](#funktionen)
5. [Dokumentations-√úbersicht](#dokumentations-√ºbersicht)
6. [API-Referenz](#api-referenz)
7. [Datenbank-Schema](#datenbank-schema)
8. [Deployment](#deployment)
9. [Testing & Validierung](#testing--validierung)
10. [Troubleshooting](#troubleshooting)

---

## üéØ Projekt-√úbersicht

### Was ist der ML Training Service?

Ein vollst√§ndiger Machine Learning Service f√ºr Kryptow√§hrungs-Datenanalyse, der:

- ‚úÖ **ML-Modelle trainiert** (Random Forest, XGBoost)
- ‚úÖ **Modelle testet** auf neuen Daten
- ‚úÖ **Modelle vergleicht** um das beste zu finden
- ‚úÖ **Zeitbasierte Vorhersagen** macht (z.B. "Steigt in 5 Min um 30%")
- ‚úÖ **Feature-Engineering** f√ºr bessere Performance
- ‚úÖ **Asynchrone Job-Verarbeitung** f√ºr lange Trainings
- ‚úÖ **Web-UI** f√ºr einfache Bedienung
- ‚úÖ **REST API** f√ºr Automatisierung

### Technologie-Stack

- **Backend:** FastAPI (Python 3.11)
- **Frontend:** Streamlit
- **Datenbank:** PostgreSQL (extern)
- **ML-Frameworks:** Scikit-learn, XGBoost
- **Job-Queue:** Asyncio-basiert
- **Monitoring:** Prometheus Metriken
- **Deployment:** Docker, Coolify

---

## üöÄ Schnellstart

### Voraussetzungen

- Docker Desktop
- PostgreSQL Datenbank (extern)
- Python 3.11+ (f√ºr lokale Entwicklung)

### Installation

1. **Repository klonen:**
   ```bash
   git clone <repository-url>
   cd ml-training-service
   ```

2. **Docker Container starten:**
   ```bash
   docker-compose up -d
   ```

3. **Service pr√ºfen:**
   - FastAPI: http://localhost:8000
   - Streamlit UI: http://localhost:8501
   - API Docs: http://localhost:8000/docs
   - Health Check: http://localhost:8000/health

4. **Datenbank-Schema anwenden:**
   ```bash
   psql -h <db-host> -U postgres -d crypto_bot -f sql/schema.sql
   ```

### Erste Schritte

1. **Web-UI √∂ffnen:** http://localhost:8501
2. **Modell erstellen:** "Neues Modell erstellen" ‚Üí Parameter eingeben ‚Üí "Modell erstellen"
3. **Modell testen:** "Modell testen" ‚Üí Zeitraum w√§hlen ‚Üí "Test starten"
4. **Ergebnisse ansehen:** "√úbersicht" ‚Üí Modell ausw√§hlen ‚Üí "Details anzeigen"

---

## üèóÔ∏è Architektur

### Projekt-Struktur

```
ml-training-service/
‚îú‚îÄ‚îÄ app/                          # Hauptanwendung
‚îÇ   ‚îú‚îÄ‚îÄ api/                      # REST API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py             # API Endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py            # Pydantic Schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validators.py         # Validierungs-Logik
‚îÇ   ‚îú‚îÄ‚îÄ database/                 # Datenbank-Operationen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connection.py         # DB-Verbindung
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py             # DB-Interaktionen
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py              # JSONB-Helper
‚îÇ   ‚îú‚îÄ‚îÄ queue/                    # Job-Verarbeitung
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ job_manager.py        # Job-Queue Manager
‚îÇ   ‚îú‚îÄ‚îÄ training/                 # ML Training-Logik
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engine.py              # Training-Engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py # Feature-Engineering
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_loader.py       # Modell-Laden/Testen
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # Utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Konfiguration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py         # Custom Exceptions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py     # Logging-Setup
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py            # Prometheus Metriken
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # FastAPI App
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py          # Streamlit UI
‚îú‚îÄ‚îÄ docs/                         # Dokumentation
‚îú‚îÄ‚îÄ tests/                         # Test-Scripts
‚îú‚îÄ‚îÄ sql/                          # SQL-Schema und Queries
‚îú‚îÄ‚îÄ models/                       # Gespeicherte ML-Modelle (.pkl)
‚îú‚îÄ‚îÄ docker-compose.yml            # Docker-Konfiguration
‚îú‚îÄ‚îÄ Dockerfile                    # Docker-Image
‚îî‚îÄ‚îÄ requirements.txt              # Python-Abh√§ngigkeiten
```

### Datenfluss

```
API Request (Web UI / REST API)
    ‚Üì
FastAPI Routes (app/api/routes.py)
    ‚Üì
Job erstellen (ml_jobs Tabelle)
    ‚Üì
Job Queue (app/queue/job_manager.py)
    ‚Üì
Training Engine (app/training/engine.py)
    ‚Üì
Datenbank (PostgreSQL)
    ‚Üì
Ergebnis speichern (ml_models, ml_test_results, ml_comparisons)
```

### Komponenten

#### 1. REST API (FastAPI)
- **Datei:** `app/api/routes.py`
- **Funktion:** REST Endpoints f√ºr Modell-Erstellung, Testing, Vergleich
- **Port:** 8000

#### 2. Web-UI (Streamlit)
- **Datei:** `app/streamlit_app.py`
- **Funktion:** Benutzerfreundliche Oberfl√§che
- **Port:** 8501

#### 3. Job Queue
- **Datei:** `app/queue/job_manager.py`
- **Funktion:** Asynchrone Verarbeitung von Trainings/Test-Jobs
- **Status:** PENDING ‚Üí RUNNING ‚Üí COMPLETED/FAILED

#### 4. Training Engine
- **Datei:** `app/training/engine.py`
- **Funktion:** ML-Modell-Training (Random Forest, XGBoost)
- **Features:** Feature-Engineering, SMOTE, TimeSeriesSplit

#### 5. Feature Engineering
- **Datei:** `app/training/feature_engineering.py`
- **Funktion:** Erstellt zus√§tzliche Features (Momentum, Volatilit√§t, etc.)

---

## ‚öôÔ∏è Funktionen

### 1. Modell-Erstellung

**Unterst√ºtzte Modell-Typen:**
- Random Forest
- XGBoost

**Vorhersage-Typen:**
- **Klassisch:** Schwellwert-basiert (z.B. `market_cap_close > 10000`)
- **Zeitbasiert:** Zuk√ºnftige Preis√§nderung (z.B. "Steigt in 5 Min um 30%")

**Features:**
- ‚úÖ Feature-Engineering (optional)
- ‚úÖ SMOTE (Oversampling, optional)
- ‚úÖ TimeSeriesSplit (Cross-Validation, optional)
- ‚úÖ Hyperparameter-Tuning

**Dokumentation:** [MODELL_ERSTELLUNG_KOMPLETT_DOKUMENTATION.md](MODELL_ERSTELLUNG_KOMPLETT_DOKUMENTATION.md)

### 2. Modell-Testing

**Funktionen:**
- Test auf neuen Daten
- Train vs. Test Vergleich
- Overlap-Pr√ºfung
- Umfassende Metriken

**Metriken:**
- Accuracy, F1-Score, Precision, Recall
- ROC-AUC, MCC, FPR, FNR
- Confusion Matrix
- Simulated Profit

**Dokumentation:** [MODELL_TEST_VERGLEICH_KOMPLETT_DOKUMENTATION.md](MODELL_TEST_VERGLEICH_KOMPLETT_DOKUMENTATION.md)

### 3. Modell-Vergleich

**Funktionen:**
- Zwei Modelle auf denselben Daten testen
- Automatische Gewinner-Bestimmung
- Detaillierter Vergleich

**Dokumentation:** [MODELL_TEST_VERGLEICH_KOMPLETT_DOKUMENTATION.md](MODELL_TEST_VERGLEICH_KOMPLETT_DOKUMENTATION.md)

### 4. Feature-Engineering

**Erstellte Features:**
- Price Momentum (ROC, Change)
- Volatility (Preis-Schwankungen)
- Market Cap Velocity
- Price Range
- Volume Patterns

**Dokumentation:** [VALIDIERUNG_FEATURE_ENGINEERING.md](VALIDIERUNG_FEATURE_ENGINEERING.md)

---

## üìö Dokumentations-√úbersicht

### Kern-Dokumentationen

| Dokument | Beschreibung | Status |
|----------|--------------|--------|
| **[COMPLETE_WORKFLOW_DOKUMENTATION.md](COMPLETE_WORKFLOW_DOKUMENTATION.md)** | Vollst√§ndiger Workflow von Erstellung bis Testing | ‚úÖ Aktuell |
| **[MODELL_ERSTELLUNG_KOMPLETT_DOKUMENTATION.md](MODELL_ERSTELLUNG_KOMPLETT_DOKUMENTATION.md)** | Detaillierte Modell-Erstellung | ‚úÖ Aktuell |
| **[MODELL_TEST_VERGLEICH_KOMPLETT_DOKUMENTATION.md](MODELL_TEST_VERGLEICH_KOMPLETT_DOKUMENTATION.md)** | Testing und Vergleich | ‚úÖ Aktuell |
| **[DATABASE_SCHEMA.md](DATABASE_SCHEMA.md)** | Datenbank-Schema | ‚úÖ Aktuell |

### API & Integration

| Dokument | Beschreibung | Status |
|----------|--------------|--------|
| **[N8N_API_ANLEITUNG.md](N8N_API_ANLEITUNG.md)** | API-Nutzung mit n8n | ‚úÖ Aktuell |
| **[API_BASE_URL_ERKLAERUNG.md](API_BASE_URL_ERKLAERUNG.md)** | API-Konfiguration | ‚úÖ Aktuell |

### Deployment

| Dokument | Beschreibung | Status |
|----------|--------------|--------|
| **[COOLIFY_DEPLOYMENT.md](COOLIFY_DEPLOYMENT.md)** | Deployment auf Coolify | ‚úÖ Aktuell |
| **[COOLIFY_QUICK_START.md](COOLIFY_QUICK_START.md)** | Schnellstart Coolify | ‚úÖ Aktuell |
| **[DEPLOYMENT.md](DEPLOYMENT.md)** | Allgemeine Deployment-Anleitung | ‚úÖ Aktuell |

### Testing & Validierung

| Dokument | Beschreibung | Status |
|----------|--------------|--------|
| **[TESTBERICHT_VALIDIERUNG.md](TESTBERICHT_VALIDIERUNG.md)** | Vollst√§ndiger Testbericht | ‚úÖ Aktuell |
| **[VALIDIERUNG_FEATURE_ENGINEERING.md](VALIDIERUNG_FEATURE_ENGINEERING.md)** | Feature-Engineering Validierung | ‚úÖ Aktuell |
| **[ERKLAERUNG_F1_SCORE_PROBLEM.md](ERKLAERUNG_F1_SCORE_PROBLEM.md)** | Erkl√§rung F1-Score = 0 | ‚úÖ Aktuell |
| **[VERGLEICH_MODell_1_VS_3.md](VERGLEICH_MODell_1_VS_3.md)** | Modell-Vergleich | ‚úÖ Aktuell |

### Monitoring

| Dokument | Beschreibung | Status |
|----------|--------------|--------|
| **[GRAFANA_DASHBOARD_ANLEITUNG.md](GRAFANA_DASHBOARD_ANLEITUNG.md)** | Grafana Setup | ‚úÖ Aktuell |

### Historische Dokumentationen

Diese Dokumentationen sind f√ºr Referenzzwecke behalten, aber m√∂glicherweise veraltet:

- `PHASE1_*.md` - Phase 1 Implementierung
- `PHASE2_*.md` - Phase 2 Implementierung
- `TEST_PHASE*.md` - Test-Ergebnisse
- `STATUS_UEBERSICHT.md` - Alte Status-√úbersicht

---

## üîå API-Referenz

### Basis-URL

- **Lokal:** `http://localhost:8000/api`
- **Produktion:** `http://100.76.209.59:8005/api`

### Wichtige Endpoints

#### Modell-Erstellung
```
POST /api/models/create
```

#### Modell-Testing
```
POST /api/models/{model_id}/test
```

#### Modell-Vergleich
```
POST /api/models/compare
```

#### Modell-Liste
```
GET /api/models
```

#### Job-Status
```
GET /api/queue/{job_id}
```

**Vollst√§ndige API-Dokumentation:** http://localhost:8000/docs (Swagger UI)

**Detaillierte Anleitung:** [N8N_API_ANLEITUNG.md](N8N_API_ANLEITUNG.md)

---

## üóÑÔ∏è Datenbank-Schema

### Haupt-Tabellen

#### `ml_models`
Speichert alle trainierten Modelle.

**Wichtige Felder:**
- `id`, `name`, `model_type`
- `train_start`, `train_end`
- `features` (JSONB)
- `params` (JSONB)
- `training_accuracy`, `training_f1`
- `confusion_matrix` (JSONB)
- `feature_importance` (JSONB)

#### `ml_test_results`
Speichert alle Test-Ergebnisse.

**Wichtige Felder:**
- `id`, `model_id`
- `test_start`, `test_end`
- `accuracy`, `f1_score`, `precision_score`, `recall`
- `confusion_matrix` (JSONB)
- `train_accuracy`, `accuracy_degradation`
- `is_overfitted`

#### `ml_comparisons`
Speichert Modell-Vergleiche.

**Wichtige Felder:**
- `id`, `model_a_id`, `model_b_id`
- `test_a_id`, `test_b_id` (Foreign Keys zu ml_test_results)
- `winner_id`
- `test_start`, `test_end`

#### `ml_jobs`
Speichert alle Jobs (Training, Testing, Vergleich).

**Wichtige Felder:**
- `id`, `job_type` (TRAIN, TEST, COMPARE)
- `status` (PENDING, RUNNING, COMPLETED, FAILED)
- `progress` (0.0 - 1.0)
- `result_model_id`, `result_test_id`, `result_comparison_id`

**Vollst√§ndiges Schema:** [DATABASE_SCHEMA.md](DATABASE_SCHEMA.md)  
**SQL-Schema:** `sql/schema.sql`

---

## üöÄ Deployment

### Lokal (Docker)

```bash
docker-compose up -d
```

### Coolify

**Anleitung:** [COOLIFY_DEPLOYMENT.md](COOLIFY_DEPLOYMENT.md)

**Schnellstart:** [COOLIFY_QUICK_START.md](COOLIFY_QUICK_START.md)

### Umgebungsvariablen

```bash
DB_HOST=your-db-host
DB_PORT=5432
DB_NAME=crypto_bot
DB_USER=postgres
DB_PASSWORD=your-password
```

---

## üß™ Testing & Validierung

### Automatisierte Tests

**Validierungs-Scripts:**
- `tests/comprehensive_validation.py` - Systemweite Validierung
- `tests/validate_model_test_results.py` - Einzelne Validierung
- `tests/final_live_test.py` - Live-Test

**Ausf√ºhrung:**
```bash
API_BASE_URL="http://localhost:8000/api" python3 tests/comprehensive_validation.py
```

### Testbericht

**Vollst√§ndiger Testbericht:** [TESTBERICHT_VALIDIERUNG.md](TESTBERICHT_VALIDIERUNG.md)

**Ergebnis:** ‚úÖ Alle Tests bestanden, System zu 100% validiert

---

## üîß Troubleshooting

### H√§ufige Probleme

#### 1. F1-Score = 0

**Problem:** Modell macht keine positiven Vorhersagen.

**L√∂sung:** 
- Feature-Engineering aktivieren
- Mehr Features verwenden
- SMOTE aktivieren
- Weniger strenge Anforderungen

**Dokumentation:** [ERKLAERUNG_F1_SCORE_PROBLEM.md](ERKLAERUNG_F1_SCORE_PROBLEM.md)

#### 2. Job bleibt bei PENDING

**Problem:** Job wird nicht verarbeitet.

**L√∂sung:**
- Job Worker pr√ºfen: `docker-compose logs ml-training`
- Datenbank-Verbindung pr√ºfen
- Ressourcen pr√ºfen (CPU, RAM)

#### 3. Feature-Engineering funktioniert nicht

**Problem:** Keine Feature-Engineering Features erstellt.

**L√∂sung:**
- Parameter pr√ºfen: `use_engineered_features: true`
- Logs pr√ºfen: Sollte "Erstelle Pump-Detection Features" zeigen

**Dokumentation:** [VALIDIERUNG_FEATURE_ENGINEERING.md](VALIDIERUNG_FEATURE_ENGINEERING.md)

#### 4. Datenbank-Verbindungsfehler

**Problem:** Kann nicht zur Datenbank verbinden.

**L√∂sung:**
- DB-Host, Port, Credentials pr√ºfen
- Firewall-Regeln pr√ºfen
- Datenbank erreichbar?

---

## üìä Monitoring

### Prometheus Metriken

**Endpoint:** `http://localhost:8000/metrics`

**Wichtige Metriken:**
- `ml_active_jobs` - Anzahl aktiver Jobs
- `ml_job_progress_percent` - Job-Fortschritt
- `ml_models_total` - Anzahl Modelle
- `ml_service_uptime_seconds` - Uptime

### Grafana Dashboard

**Anleitung:** [GRAFANA_DASHBOARD_ANLEITUNG.md](GRAFANA_DASHBOARD_ANLEITUNG.md)

**Dashboard JSON:** `docs/grafana_dashboard.json`

---

## üîÑ Workflow-Beispiel

### 1. Modell erstellen

1. Web-UI √∂ffnen: http://localhost:8501
2. "Neues Modell erstellen"
3. Parameter eingeben:
   - Modell-Typ: XGBoost
   - Features: price_open, price_high, price_low, price_close
   - Feature-Engineering: ‚úÖ Aktiviert
   - Zeitbasierte Vorhersage: 5 Min, 30%
4. "Modell erstellen" klicken
5. Warten bis Job abgeschlossen

### 2. Modell testen

1. "Modell testen"
2. Modell ausw√§hlen
3. Test-Zeitraum w√§hlen
4. "Test starten"
5. Ergebnisse ansehen

### 3. Modelle vergleichen

1. "Modelle vergleichen"
2. Zwei Modelle ausw√§hlen
3. Test-Zeitraum w√§hlen
4. "Vergleich starten"
5. Gewinner ansehen

---

## üìù Changelog

### Version 2.0 (24. Dezember 2025)

- ‚úÖ Schema-Verbesserungen (ml_test_results, ml_comparisons)
- ‚úÖ Feature-Engineering implementiert
- ‚úÖ SMOTE (Oversampling) implementiert
- ‚úÖ TimeSeriesSplit implementiert
- ‚úÖ Zus√§tzliche Metriken (MCC, FPR, FNR, ROC-AUC)
- ‚úÖ Train vs. Test Vergleich
- ‚úÖ Umfassende Validierung
- ‚úÖ Grafana Dashboard
- ‚úÖ Coolify Deployment

### Version 1.0 (Initial)

- ‚úÖ Basis-Funktionalit√§t
- ‚úÖ Modell-Erstellung
- ‚úÖ Modell-Testing
- ‚úÖ Modell-Vergleich

---

## üìû Support

Bei Fragen oder Problemen:

1. **Dokumentation pr√ºfen:** Siehe [Dokumentations-√úbersicht](#dokumentations-√ºbersicht)
2. **Logs pr√ºfen:** `docker-compose logs ml-training`
3. **API testen:** http://localhost:8000/docs

---

**Letzte Aktualisierung:** 24. Dezember 2025  
**Version:** 2.0  
**Status:** ‚úÖ Produktionsreif

