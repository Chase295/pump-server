# ğŸ¤– ML Training Service

Machine Learning Training Service fÃ¼r KryptowÃ¤hrungs-Datenanalyse.

**Version:** 2.1
**Status:** âœ… Produktionsreif
**Stand:** 6. Januar 2026

## ğŸ“‹ Ãœbersicht

Dieser Service ermÃ¶glicht das Training, Testen und Vergleichen von ML-Modellen (Random Forest, XGBoost) fÃ¼r KryptowÃ¤hrungs-Daten aus der `coin_metrics` Tabelle.

### Hauptfunktionen

- âœ… **Modell-Training** (Random Forest, XGBoost)
- âœ… **Zeitbasierte Vorhersagen** (z.B. "Steigt in 5 Min um 30%")
- âœ… **Feature-Engineering** fÃ¼r bessere Performance
- âœ… **Modell-Testing** auf neuen Daten
- âœ… **Modell-Vergleich** um das beste zu finden
- âœ… **Asynchrone Job-Verarbeitung**
- âœ… **Moderne Web-UI** (Material-UI) mit Trading Dashboard
- âœ… **Trading Command Center** - ModelDetails mit allen Infos
- âœ… **REST API** fÃ¼r Automatisierung
- âœ… **Prometheus Metriken** fÃ¼r Monitoring

## ğŸš€ Schnellstart

### Voraussetzungen
- Docker Desktop
- PostgreSQL Datenbank (extern)

### Installation

1. **Repository klonen:**
   ```bash
   git clone <repository-url>
   cd ml-training-service
   ```

2. **Docker Container starten:**
   ```bash
   docker-compose up -d
   ```

3. **Service prÃ¼fen:**
   - FastAPI: http://localhost:8000
   - Streamlit UI: http://localhost:8501
   - API Docs: http://localhost:8000/docs
   - Health Check: http://localhost:8000/health

4. **Datenbank-Schema anwenden:**
   ```bash
   psql -h <db-host> -U postgres -d crypto_bot -f sql/schema.sql
   ```

### Erste Schritte

1. **Web-UI Ã¶ffnen:** http://localhost:8501
2. **Modell erstellen:** "Neues Modell erstellen" â†’ Parameter eingeben
3. **Modell testen:** "Modell testen" â†’ Zeitraum wÃ¤hlen
4. **Ergebnisse ansehen:** "Ãœbersicht" â†’ Modell auswÃ¤hlen

## ğŸ“ Projektstruktur

```
ml-training-service/
â”œâ”€â”€ app/                          # Hauptanwendung
â”‚   â”œâ”€â”€ api/                      # REST API (FastAPI)
â”‚   â”‚   â”œâ”€â”€ routes.py             # API Endpoints
â”‚   â”‚   â”œâ”€â”€ schemas.py            # Pydantic Schemas
â”‚   â”‚   â””â”€â”€ validators.py         # Validierungs-Logik
â”‚   â”œâ”€â”€ database/                 # Datenbank-Operationen
â”‚   â”‚   â”œâ”€â”€ connection.py         # DB-Verbindung
â”‚   â”‚   â”œâ”€â”€ models.py             # DB-Interaktionen
â”‚   â”‚   â””â”€â”€ utils.py              # JSONB-Helper
â”‚   â”œâ”€â”€ queue/                    # Job-Verarbeitung
â”‚   â”‚   â””â”€â”€ job_manager.py        # Job-Queue Manager
â”‚   â”œâ”€â”€ training/                 # ML Training-Logik
â”‚   â”‚   â”œâ”€â”€ engine.py             # Training-Engine
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py # Feature-Engineering
â”‚   â”‚   â””â”€â”€ model_loader.py       # Modell-Laden/Testen
â”‚   â”œâ”€â”€ utils/                    # Utilities
â”‚   â”‚   â”œâ”€â”€ config.py             # Konfiguration
â”‚   â”‚   â”œâ”€â”€ exceptions.py         # Custom Exceptions
â”‚   â”‚   â”œâ”€â”€ logging_config.py     # Logging-Setup
â”‚   â”‚   â””â”€â”€ metrics.py            # Prometheus Metriken
â”‚   â”œâ”€â”€ main.py                   # FastAPI App
â”‚   â””â”€â”€ streamlit_app.py          # Streamlit UI
â”œâ”€â”€ docs/                         # Dokumentation
â”‚   â””â”€â”€ 00_GESAMT_DOKUMENTATION.md # â­ Start hier!
â”œâ”€â”€ tests/                        # Test-Scripts
â”œâ”€â”€ sql/                          # SQL-Schema und Queries
â”œâ”€â”€ models/                       # Gespeicherte ML-Modelle (.pkl)
â”œâ”€â”€ docker-compose.yml            # Docker-Konfiguration
â”œâ”€â”€ Dockerfile                    # Docker-Image
â””â”€â”€ requirements.txt              # Python-AbhÃ¤ngigkeiten
```

## ğŸ“š Dokumentation

### â­ Start hier: [Gesamt-Dokumentation](docs/00_GESAMT_DOKUMENTATION.md)

**Wichtige Dokumentationen:**

- **[Gesamt-Dokumentation](docs/00_GESAMT_DOKUMENTATION.md)** - VollstÃ¤ndige Ãœbersicht
- **[Modell-Erstellung](docs/MODELL_ERSTELLUNG_KOMPLETT_DOKUMENTATION.md)** - Detaillierte Anleitung
- **[Modell-Test & Vergleich](docs/MODELL_TEST_VERGLEICH_KOMPLETT_DOKUMENTATION.md)** - Testing-Anleitung
- **[Datenbank-Schema](docs/DATABASE_SCHEMA.md)** - Schema-Dokumentation
- **[API-Anleitung](docs/N8N_API_ANLEITUNG.md)** - API-Nutzung
- **[Deployment](docs/COOLIFY_DEPLOYMENT.md)** - Coolify Deployment
- **[Testbericht](docs/TESTBERICHT_VALIDIERUNG.md)** - VollstÃ¤ndiger Testbericht

**VollstÃ¤ndige Ãœbersicht:** Siehe [docs/README.md](docs/README.md)

## ğŸ§ª Tests

Tests befinden sich im `tests/` Ordner:

```bash
# End-to-End Tests ausfÃ¼hren
python tests/test_e2e.py
python tests/test_e2e_xgboost.py
```

## ğŸ”§ Konfiguration

### Umgebungsvariablen

Die Datenbank-Verbindung wird in `app/database/connection.py` konfiguriert:

```python
DB_HOST = "10.0.128.18"
DB_PORT = 5432
DB_NAME = "crypto_bot"
DB_USER = "postgres"
DB_PASSWORD = "your_password"
```

## ğŸ“Š Features

- âœ… Modell-Training (Random Forest, XGBoost)
- âœ… Klassische Vorhersagen (Schwellwert-basiert)
- âœ… Zeitbasierte Vorhersagen (Steigt/FÃ¤llt in X Minuten um X%)
- âœ… Modell-Testing auf neuen Daten
- âœ… Modell-Vergleich (2 Modelle auf denselben Daten)
- âœ… Asynchrone Job-Verarbeitung
- âœ… Streamlit Web-UI
- âœ… REST API
- âœ… Prometheus Metriken

## ğŸ› ï¸ Entwicklung

### Lokale Entwicklung

```bash
# Container neu bauen
docker-compose up -d --build

# Logs anzeigen
docker-compose logs -f

# In Container einsteigen
docker-compose exec ml-training bash
```

### Code-Struktur

- **API Routes:** `app/api/routes.py`
- **Schemas:** `app/api/schemas.py`
- **Database Models:** `app/database/models.py`
- **Training Engine:** `app/training/engine.py`
- **Feature Engineering:** `app/training/feature_engineering.py`
- **Job Manager:** `app/queue/job_manager.py`

## ğŸ“ Lizenz

ProprietÃ¤r

---

**Erstellt:** 2024  
**Version:** 1.0
