# Lokale Entwicklung - mit direkten Port-Mappings
# FÃ¼r Coolify verwende docker-compose.yml (ohne Port-Mappings)

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ml-prediction-service-backend
    restart: unless-stopped
    environment:
      - DB_DSN=${DB_DSN}
      - TRAINING_SERVICE_API_URL=${TRAINING_SERVICE_API_URL}
      - MODEL_STORAGE_PATH=/app/models
      - N8N_WEBHOOK_URL=${N8N_WEBHOOK_URL:-}
    volumes:
      - ./models:/app/models
      - ./logs:/app/logs
      - ./tmp:/tmp/models
      - ./config:/app/config
    ports:
      - "8000:8000"  # Direkter Zugriff auf Backend-API
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - ml-prediction-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.frontend
    container_name: ml-prediction-service-frontend
    restart: unless-stopped
    ports:
      - "3003:3000"  # Direkter Zugriff auf Frontend
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - ml-prediction-network

networks:
  ml-prediction-network:
    driver: bridge
